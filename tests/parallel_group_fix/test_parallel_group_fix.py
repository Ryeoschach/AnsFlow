#!/usr/bin/env python3
"""
éªŒè¯å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿®å¤æ•ˆæœ
"""

import os
import sys
import django

# è®¾ç½®Djangoç¯å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ansflow.settings')
sys.path.append('/Users/creed/Workspace/OpenSource/ansflow/backend/django_service')

django.setup()

from pipelines.models import Pipeline, PipelineStep, ParallelGroup
from pipelines.serializers import ParallelGroupSerializer

def test_parallel_group_steps_association():
    """æµ‹è¯•å¹¶è¡Œç»„æ­¥éª¤å…³è”åŠŸèƒ½"""
    
    print("ğŸ§ª æµ‹è¯•å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿®å¤æ•ˆæœ")
    print("=" * 50)
    
    try:
        # 1. è·å–æµ‹è¯•æ•°æ®
        print("1ï¸âƒ£ è·å–æµ‹è¯•æ•°æ®...")
        
        # è·å–æµæ°´çº¿
        pipeline = Pipeline.objects.first()
        if not pipeline:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æµæ°´çº¿")
            return False
        
        print(f"âœ… ä½¿ç”¨æµæ°´çº¿: {pipeline.name} (ID: {pipeline.id})")
        
        # è·å–æ­¥éª¤
        steps = pipeline.steps.all()
        if len(steps) < 2:
            print("âŒ æ­¥éª¤æ•°é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘2ä¸ªæ­¥éª¤")
            return False
        
        print(f"âœ… æµæ°´çº¿åŒ…å« {len(steps)} ä¸ªæ­¥éª¤")
        for step in steps:
            group_info = f" â†’ å¹¶è¡Œç»„: {step.parallel_group}" if step.parallel_group else " â†’ æ— å¹¶è¡Œç»„"
            print(f"  - {step.name} (ID: {step.id}){group_info}")
        
        # 2. åˆ›å»ºæµ‹è¯•å¹¶è¡Œç»„
        print("2ï¸âƒ£ åˆ›å»ºæµ‹è¯•å¹¶è¡Œç»„...")
        
        test_steps = [steps[0].id, steps[1].id]  # é€‰æ‹©å‰ä¸¤ä¸ªæ­¥éª¤
        
        group_data = {
            'id': 'test_steps_association',
            'name': 'æ­¥éª¤å…³è”æµ‹è¯•ç»„',
            'description': 'æµ‹è¯•æ­¥éª¤å…³è”ä¿®å¤çš„å¹¶è¡Œç»„',
            'pipeline': pipeline.id,
            'sync_policy': 'wait_all',
            'timeout_seconds': 3600,
            'steps': test_steps
        }
        
        print(f"ğŸ“ åˆ›å»ºå¹¶è¡Œç»„ï¼ŒåŒ…å«æ­¥éª¤: {test_steps}")
        
        serializer = ParallelGroupSerializer(data=group_data)
        if serializer.is_valid():
            parallel_group = serializer.save()
            print(f"âœ… å¹¶è¡Œç»„åˆ›å»ºæˆåŠŸ: {parallel_group.id}")
        else:
            print(f"âŒ å¹¶è¡Œç»„åˆ›å»ºå¤±è´¥: {serializer.errors}")
            return False
        
        # 3. éªŒè¯æ­¥éª¤å…³è”
        print("3ï¸âƒ£ éªŒè¯æ­¥éª¤å…³è”...")
        
        # é‡æ–°è·å–æ­¥éª¤æ•°æ®
        updated_steps = pipeline.steps.all()
        associated_steps = updated_steps.filter(parallel_group=parallel_group.id)
        
        print(f"ğŸ“Š éªŒè¯ç»“æœ:")
        print(f"  æœŸæœ›å…³è”æ­¥éª¤æ•°: {len(test_steps)}")
        print(f"  å®é™…å…³è”æ­¥éª¤æ•°: {associated_steps.count()}")
        
        if associated_steps.count() == len(test_steps):
            print("âœ… æ­¥éª¤å…³è”æˆåŠŸ!")
            for step in associated_steps:
                print(f"  âœ… æ­¥éª¤ '{step.name}' (ID: {step.id}) å·²å…³è”åˆ°å¹¶è¡Œç»„")
        else:
            print("âŒ æ­¥éª¤å…³è”å¤±è´¥!")
            return False
        
        # 4. æµ‹è¯•åºåˆ—åŒ–å™¨çš„è¯»å–åŠŸèƒ½
        print("4ï¸âƒ£ æµ‹è¯•åºåˆ—åŒ–å™¨è¯»å–åŠŸèƒ½...")
        
        read_serializer = ParallelGroupSerializer(parallel_group)
        serialized_data = read_serializer.data
        
        print(f"ğŸ“¤ åºåˆ—åŒ–ç»“æœ:")
        print(f"  å¹¶è¡Œç»„ID: {serialized_data['id']}")
        print(f"  å¹¶è¡Œç»„åç§°: {serialized_data['name']}")
        print(f"  åŒ…å«æ­¥éª¤: {serialized_data['steps']}")
        
        if set(serialized_data['steps']) == set(test_steps):
            print("âœ… åºåˆ—åŒ–å™¨è¯»å–æ­£ç¡®!")
        else:
            print("âŒ åºåˆ—åŒ–å™¨è¯»å–é”™è¯¯!")
            return False
        
        # 5. æµ‹è¯•æ›´æ–°åŠŸèƒ½
        print("5ï¸âƒ£ æµ‹è¯•æ›´æ–°åŠŸèƒ½...")
        
        # åªä¿ç•™ç¬¬ä¸€ä¸ªæ­¥éª¤
        update_data = {
            'steps': [test_steps[0]]
        }
        
        update_serializer = ParallelGroupSerializer(parallel_group, data=update_data, partial=True)
        if update_serializer.is_valid():
            updated_group = update_serializer.save()
            print(f"âœ… å¹¶è¡Œç»„æ›´æ–°æˆåŠŸ")
        else:
            print(f"âŒ å¹¶è¡Œç»„æ›´æ–°å¤±è´¥: {update_serializer.errors}")
            return False
        
        # éªŒè¯æ›´æ–°ç»“æœ
        final_steps = pipeline.steps.filter(parallel_group=parallel_group.id)
        if final_steps.count() == 1 and final_steps.first().id == test_steps[0]:
            print("âœ… æ›´æ–°åŠŸèƒ½æ­£å¸¸!")
        else:
            print("âŒ æ›´æ–°åŠŸèƒ½å¼‚å¸¸!")
            return False
        
        # 6. æ¸…ç†æµ‹è¯•æ•°æ®
        print("6ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        
        # æ¸…é™¤æ­¥éª¤å…³è”
        PipelineStep.objects.filter(parallel_group=parallel_group.id).update(parallel_group='')
        
        # åˆ é™¤å¹¶è¡Œç»„
        parallel_group.delete()
        print("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_current_state():
    """æ£€æŸ¥å½“å‰çš„æ•°æ®çŠ¶æ€"""
    
    print("\nğŸ” æ£€æŸ¥å½“å‰æ•°æ®çŠ¶æ€")
    print("=" * 30)
    
    # è·å–æ‰€æœ‰æµæ°´çº¿
    pipelines = Pipeline.objects.all()
    print(f"ğŸ“‹ ç³»ç»Ÿä¸­å…±æœ‰ {pipelines.count()} ä¸ªæµæ°´çº¿")
    
    for pipeline in pipelines:
        print(f"\næµæ°´çº¿: {pipeline.name} (ID: {pipeline.id})")
        
        # è·å–æ­¥éª¤
        steps = pipeline.steps.all()
        print(f"æ­¥éª¤æ•°é‡: {steps.count()}")
        
        for step in steps:
            group_info = f" â†’ å¹¶è¡Œç»„: {step.parallel_group}" if step.parallel_group else " â†’ æ— å¹¶è¡Œç»„"
            print(f"  {step.name} (ID: {step.id}){group_info}")
        
        # è·å–å¹¶è¡Œç»„
        groups = pipeline.parallel_groups.all()
        print(f"å¹¶è¡Œç»„æ•°é‡: {groups.count()}")
        
        for group in groups:
            associated_steps = steps.filter(parallel_group=group.id)
            print(f"  - {group.name} (ID: {group.id})")
            print(f"    å±äºè¯¥ç»„çš„æ­¥éª¤: {associated_steps.count()} ä¸ª")
            for step in associated_steps:
                print(f"      * {step.name} (ID: {step.id})")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ”§ å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿®å¤éªŒè¯")
    print("=" * 50)
    
    # æ£€æŸ¥å½“å‰çŠ¶æ€
    check_current_state()
    
    # è¿è¡Œæµ‹è¯•
    success = test_parallel_group_steps_association()
    
    if success:
        print("\nâœ… ä¿®å¤éªŒè¯æˆåŠŸ!")
        print("ğŸ“ ä¿®å¤æ€»ç»“:")
        print("  1. ParallelGroupSerializerç°åœ¨æ­£ç¡®å¤„ç†stepså­—æ®µ")
        print("  2. åˆ›å»ºå¹¶è¡Œç»„æ—¶ä¼šè‡ªåŠ¨å…³è”æ­¥éª¤")
        print("  3. æ›´æ–°å¹¶è¡Œç»„æ—¶ä¼šåŒæ­¥æ›´æ–°æ­¥éª¤å…³è”")
        print("  4. åºåˆ—åŒ–æ—¶ä¼šæ­£ç¡®è¿”å›å…³è”çš„æ­¥éª¤ID")
        
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. é‡å¯DjangoæœåŠ¡å™¨ä»¥åº”ç”¨ä¿®å¤")
        print("  2. åœ¨å‰ç«¯æµ‹è¯•å¹¶è¡Œç»„ç®¡ç†åŠŸèƒ½")
        print("  3. éªŒè¯æ­¥éª¤å…³è”æ˜¯å¦æ­£ç¡®ä¿å­˜å’Œæ˜¾ç¤º")
    else:
        print("\nâŒ ä¿®å¤éªŒè¯å¤±è´¥!")
        print("è¯·æ£€æŸ¥ä»£ç ä¿®å¤æ˜¯å¦æ­£ç¡®")

if __name__ == "__main__":
    main()
