#!/usr/bin/env python3
"""
æµ‹è¯•ä¿å­˜æµæ°´çº¿åå¹¶è¡Œç»„å…³è”æ˜¯å¦ä¿æŒ
"""
import os
import sys
import django
from django.conf import settings

# è®¾ç½®Djangoç¯å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ansflow.settings.development')
django.setup()

from pipelines.models import Pipeline, PipelineStep, ParallelGroup
from pipelines.serializers import ParallelGroupSerializer, PipelineSerializer

def test_pipeline_save_with_parallel_groups():
    """æµ‹è¯•ä¿å­˜æµæ°´çº¿åå¹¶è¡Œç»„å…³è”æ˜¯å¦ä¿æŒ"""
    
    print("ğŸ§ª æµ‹è¯•ä¿å­˜æµæ°´çº¿åå¹¶è¡Œç»„å…³è”ä¿æŒ...")
    
    # 1. è·å–æµ‹è¯•æµæ°´çº¿
    try:
        pipeline = Pipeline.objects.get(id=26)
        print(f"âœ… æ‰¾åˆ°æµ‹è¯•æµæ°´çº¿: {pipeline.name} (ID: {pipeline.id})")
    except Pipeline.DoesNotExist:
        print("âŒ æœªæ‰¾åˆ°æµæ°´çº¿ID 26")
        return
    
    # 2. æ£€æŸ¥å½“å‰æ­¥éª¤å’Œå¹¶è¡Œç»„çŠ¶æ€
    steps = pipeline.steps.all()
    groups = pipeline.parallel_groups.all()
    
    print(f"\nğŸ“Š å½“å‰çŠ¶æ€:")
    print(f"  - æ­¥éª¤æ•°: {steps.count()}")
    print(f"  - å¹¶è¡Œç»„æ•°: {groups.count()}")
    
    # æ˜¾ç¤ºæ­¥éª¤çš„å¹¶è¡Œç»„å…³è”
    print(f"\nğŸ“‹ æ­¥éª¤çš„å¹¶è¡Œç»„å…³è”:")
    for step in steps:
        print(f"  - æ­¥éª¤ {step.id} ({step.name}): parallel_group = '{step.parallel_group}'")
    
    # 3. ç¡®ä¿æœ‰ä¸€äº›å¹¶è¡Œç»„å…³è”ï¼ˆå¦‚æœæ²¡æœ‰ï¼Œå…ˆåˆ›å»ºä¸€äº›ï¼‰
    test_group = None
    for group in groups:
        group_id_str = str(group.id)
        associated_steps = steps.filter(parallel_group=group_id_str)
        if associated_steps.exists():
            test_group = group
            break
    
    if not test_group and groups.exists():
        # ä¸ºç¬¬ä¸€ä¸ªå¹¶è¡Œç»„åˆ†é…ä¸€äº›æ­¥éª¤
        test_group = groups.first()
        test_steps = list(steps[:2])  # é€‰æ‹©å‰ä¸¤ä¸ªæ­¥éª¤
        
        # æ›´æ–°æ­¥éª¤çš„å¹¶è¡Œç»„å…³è”
        for step in test_steps:
            step.parallel_group = str(test_group.id)
            step.save()
        
        print(f"\nğŸ”— å·²ä¸ºæµ‹è¯•åˆ›å»ºå¹¶è¡Œç»„å…³è”:")
        print(f"  - å¹¶è¡Œç»„: {test_group.id} ({test_group.name})")
        print(f"  - å…³è”æ­¥éª¤: {[s.id for s in test_steps]}")
    
    # 4. è®°å½•ä¿å­˜å‰çš„çŠ¶æ€
    print(f"\nğŸ“¸ ä¿å­˜å‰çš„çŠ¶æ€å¿«ç…§:")
    steps_before = {}
    for step in pipeline.steps.all():
        steps_before[step.name] = step.parallel_group
        print(f"  - {step.name}: '{step.parallel_group}'")
    
    # 5. æ¨¡æ‹Ÿå‰ç«¯ä¿å­˜æµæ°´çº¿
    print(f"\nğŸ’¾ æ¨¡æ‹Ÿä¿å­˜æµæ°´çº¿...")
    
    # æ„é€ ç±»ä¼¼å‰ç«¯çš„è¯·æ±‚æ•°æ®
    steps_data = []
    for i, step in enumerate(pipeline.steps.all().order_by('order')):
        step_data = {
            'name': step.name,
            'step_type': step.step_type,
            'description': step.description,
            'parameters': step.ansible_parameters or {},
            'order': i + 1,
            'is_active': True,
            'parallel_group': step.parallel_group  # å…³é”®ï¼šåŒ…å«å¹¶è¡Œç»„ä¿¡æ¯
        }
        steps_data.append(step_data)
        print(f"  ğŸ“‹ æ­¥éª¤æ•°æ®: {step.name} -> parallel_group: '{step.parallel_group}'")
    
    update_data = {
        'name': pipeline.name,
        'description': pipeline.description,
        'project': pipeline.project.id,
        'is_active': pipeline.is_active,
        'execution_mode': pipeline.execution_mode,
        'steps': steps_data
    }
    
    # ä½¿ç”¨ serializer ä¿å­˜
    try:
        serializer = PipelineSerializer(pipeline, data=update_data)
        if serializer.is_valid():
            updated_pipeline = serializer.save()
            print(f"âœ… æµæ°´çº¿ä¿å­˜æˆåŠŸ")
        else:
            print(f"âŒ æµæ°´çº¿ä¿å­˜éªŒè¯å¤±è´¥: {serializer.errors}")
            return
    except Exception as e:
        print(f"âŒ æµæ°´çº¿ä¿å­˜å¼‚å¸¸: {e}")
        return
    
    # 6. æ£€æŸ¥ä¿å­˜åçš„çŠ¶æ€
    print(f"\nğŸ” æ£€æŸ¥ä¿å­˜åçš„çŠ¶æ€:")
    
    updated_steps = updated_pipeline.steps.all()
    steps_after = {}
    
    print(f"ä¿å­˜åçš„æ­¥éª¤:")
    for step in updated_steps:
        steps_after[step.name] = step.parallel_group
        print(f"  - {step.name}: '{step.parallel_group}'")
    
    # 7. å¯¹æ¯”ä¿å­˜å‰å
    print(f"\nğŸ“Š ä¿å­˜å‰åå¯¹æ¯”:")
    success_count = 0
    total_count = 0
    
    for step_name in steps_before:
        before_group = steps_before[step_name]
        after_group = steps_after.get(step_name, '')
        total_count += 1
        
        if before_group == after_group:
            print(f"  âœ… {step_name}: '{before_group}' -> '{after_group}' (ä¿æŒä¸€è‡´)")
            success_count += 1
        else:
            print(f"  âŒ {step_name}: '{before_group}' -> '{after_group}' (å‘ç”Ÿå˜åŒ–)")
    
    # 8. ç»“æœæ€»ç»“
    print(f"\nğŸ¯ æµ‹è¯•ç»“æœ:")
    if success_count == total_count:
        print(f"âœ… å®Œå…¨æˆåŠŸ! {success_count}/{total_count} ä¸ªæ­¥éª¤çš„å¹¶è¡Œç»„å…³è”ä¿æŒä¸å˜")
    else:
        print(f"âŒ éƒ¨åˆ†å¤±è´¥! {success_count}/{total_count} ä¸ªæ­¥éª¤çš„å¹¶è¡Œç»„å…³è”ä¿æŒä¸å˜")
        print(f"   {total_count - success_count} ä¸ªæ­¥éª¤çš„å¹¶è¡Œç»„å…³è”ä¸¢å¤±")
    
    # 9. éªŒè¯å¹¶è¡Œç»„è§†å›¾
    print(f"\nğŸ”— éªŒè¯å¹¶è¡Œç»„è§†å›¾:")
    for group in pipeline.parallel_groups.all():
        serializer = ParallelGroupSerializer(group)
        group_data = serializer.data
        print(f"  - å¹¶è¡Œç»„ {group.id}: {len(group_data['steps'])} ä¸ªæ­¥éª¤ {group_data['steps']}")

if __name__ == "__main__":
    test_pipeline_save_with_parallel_groups()
