#!/usr/bin/env python3
"""
å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿å­˜è¯¦ç»†è°ƒè¯•è„šæœ¬
ç”¨äºéªŒè¯å‰ç«¯å‘é€çš„æ•°æ®ä¸åç«¯å¤„ç†çš„å®Œæ•´æµç¨‹
"""

import os
import sys
import json
from datetime import datetime

# æ·»åŠ Djangoé¡¹ç›®è·¯å¾„
sys.path.append('/Users/creed/Workspace/OpenSource/ansflow/backend/django_service')

# è®¾ç½®Djangoç¯å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')

import django
django.setup()

from pipelines.models import Pipeline, PipelineStep, AtomicStep, ParallelGroup
from pipelines.serializers import PipelineSerializer
from rest_framework.test import APIRequestFactory
from django.contrib.auth import get_user_model
from django.test import RequestFactory

User = get_user_model()

def debug_pipeline_save_process():
    """è¯¦ç»†è°ƒè¯•æµæ°´çº¿ä¿å­˜è¿‡ç¨‹"""
    print("=" * 80)
    print("ğŸ” å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿å­˜è¯¦ç»†è°ƒè¯•")
    print("=" * 80)
    
    try:
        # 1. è·å–æµ‹è¯•ç”¨æˆ·
        user = User.objects.first()
        if not user:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•ç”¨æˆ·")
            return
            
        print(f"ğŸ‘¤ ä½¿ç”¨æµ‹è¯•ç”¨æˆ·: {user.username}")
        
        # 2. æŸ¥æ‰¾ç°æœ‰çš„æµæ°´çº¿
        pipeline = Pipeline.objects.first()
        if not pipeline:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æµæ°´çº¿")
            return
            
        print(f"ğŸ“‹ ä½¿ç”¨æµ‹è¯•æµæ°´çº¿: {pipeline.name} (ID: {pipeline.id})")
        
        # 3. è·å–ç°æœ‰æ­¥éª¤
        existing_steps = list(pipeline.steps.all())
        existing_atomic_steps = list(pipeline.atomic_steps.all())
        
        print(f"ğŸ“ ç°æœ‰ PipelineStep æ•°é‡: {len(existing_steps)}")
        print(f"ğŸ“ ç°æœ‰ AtomicStep æ•°é‡: {len(existing_atomic_steps)}")
        
        # æ˜¾ç¤ºç°æœ‰æ­¥éª¤
        for step in existing_steps:
            print(f"  - PipelineStep: {step.name} (ID: {step.id}) - parallel_group: {step.parallel_group}")
        
        for step in existing_atomic_steps:
            print(f"  - AtomicStep: {step.name} (ID: {step.id})")
        
        # 4. è·å–ç°æœ‰å¹¶è¡Œç»„
        existing_parallel_groups = list(pipeline.parallel_groups.all())
        print(f"ğŸ”— ç°æœ‰å¹¶è¡Œç»„æ•°é‡: {len(existing_parallel_groups)}")
        
        for group in existing_parallel_groups:
            print(f"  - ParallelGroup: {group.name} (ID: {group.id}) - steps: {group.steps}")
        
        # 5. æ¨¡æ‹Ÿå‰ç«¯å‘é€çš„æ•°æ®
        print("\nğŸ“¤ æ¨¡æ‹Ÿå‰ç«¯å‘é€çš„æ›´æ–°æ•°æ®...")
        
        # æ„é€ æµ‹è¯•æ•°æ®
        test_parallel_group_id = "test_parallel_group_1"
        
        # å…ˆç¡®ä¿æœ‰å¹¶è¡Œç»„
        parallel_group, created = ParallelGroup.objects.get_or_create(
            id=test_parallel_group_id,
            pipeline=pipeline,
            defaults={
                'name': 'æµ‹è¯•å¹¶è¡Œç»„',
                'steps': []
            }
        )
        
        if created:
            print(f"âœ… åˆ›å»ºäº†æµ‹è¯•å¹¶è¡Œç»„: {parallel_group.name}")
        else:
            print(f"ğŸ“‹ ä½¿ç”¨ç°æœ‰å¹¶è¡Œç»„: {parallel_group.name}")
        
        # æ¨¡æ‹Ÿå‰ç«¯å‘é€çš„æ­¥éª¤æ•°æ®
        mock_steps_data = []
        
        # è·å–å‰ä¸¤ä¸ªæ­¥éª¤åˆ†é…åˆ°å¹¶è¡Œç»„
        step_count = 0
        for step in existing_steps[:2]:  # åªå–å‰ä¸¤ä¸ªæ­¥éª¤
            step_count += 1
            mock_steps_data.append({
                'id': step.id,
                'name': step.name,
                'step_type': step.step_type,
                'description': step.description or '',
                'parameters': step.ansible_parameters or {},
                'order': step_count,
                'is_active': True,
                'parallel_group': test_parallel_group_id,  # å…³é”®ï¼šåˆ†é…åˆ°å¹¶è¡Œç»„
                'git_credential': None
            })
        
        # å…¶ä»–æ­¥éª¤ä¸åˆ†é…åˆ°å¹¶è¡Œç»„
        for step in existing_steps[2:]:
            step_count += 1
            mock_steps_data.append({
                'id': step.id,
                'name': step.name,
                'step_type': step.step_type,
                'description': step.description or '',
                'parameters': step.ansible_parameters or {},
                'order': step_count,
                'is_active': True,
                'parallel_group': '',  # ä¸åˆ†é…åˆ°å¹¶è¡Œç»„
                'git_credential': None
            })
        
        # 6. æ„é€ å®Œæ•´çš„æ›´æ–°æ•°æ®
        update_data = {
            'name': pipeline.name,
            'description': pipeline.description,
            'project': pipeline.project_id,
            'is_active': pipeline.is_active,
            'execution_mode': pipeline.execution_mode,
            'execution_tool': pipeline.execution_tool,
            'tool_job_name': pipeline.tool_job_name,
            'tool_job_config': pipeline.tool_job_config,
            'steps': mock_steps_data
        }
        
        print(f"ğŸ“Š å‡†å¤‡ä¿å­˜ {len(mock_steps_data)} ä¸ªæ­¥éª¤:")
        for step in mock_steps_data:
            if step['parallel_group']:
                print(f"  - æ­¥éª¤ {step['name']} (ID: {step['id']}) â†’ å¹¶è¡Œç»„: {step['parallel_group']}")
            else:
                print(f"  - æ­¥éª¤ {step['name']} (ID: {step['id']}) â†’ æ— å¹¶è¡Œç»„")
        
        # 7. ä½¿ç”¨åºåˆ—åŒ–å™¨ä¿å­˜æ•°æ®
        print("\nğŸ’¾ ä½¿ç”¨åºåˆ—åŒ–å™¨ä¿å­˜æ•°æ®...")
        
        serializer = PipelineSerializer(pipeline, data=update_data, partial=True)
        
        if serializer.is_valid():
            print("âœ… æ•°æ®éªŒè¯é€šè¿‡")
            
            # ä¿å­˜æ•°æ®
            updated_pipeline = serializer.save()
            print(f"âœ… æµæ°´çº¿æ›´æ–°æˆåŠŸ: {updated_pipeline.name}")
            
            # 8. éªŒè¯ä¿å­˜ç»“æœ
            print("\nğŸ” éªŒè¯ä¿å­˜ç»“æœ...")
            
            # é‡æ–°æŸ¥è¯¢æ­¥éª¤
            updated_steps = list(updated_pipeline.steps.all())
            updated_atomic_steps = list(updated_pipeline.atomic_steps.all())
            
            print(f"ğŸ“ æ›´æ–°å PipelineStep æ•°é‡: {len(updated_steps)}")
            print(f"ğŸ“ æ›´æ–°å AtomicStep æ•°é‡: {len(updated_atomic_steps)}")
            
            # æ£€æŸ¥æ­¥éª¤çš„å¹¶è¡Œç»„åˆ†é…
            print("\nğŸ”— æ­¥éª¤çš„å¹¶è¡Œç»„åˆ†é…ç»“æœ:")
            for step in updated_steps:
                if step.parallel_group:
                    print(f"  âœ… æ­¥éª¤ {step.name} (ID: {step.id}) â†’ å¹¶è¡Œç»„: {step.parallel_group}")
                else:
                    print(f"  âšª æ­¥éª¤ {step.name} (ID: {step.id}) â†’ æ— å¹¶è¡Œç»„")
            
            # 9. éªŒè¯å¹¶è¡Œç»„çš„æ­¥éª¤åˆ—è¡¨
            print("\nğŸ”— éªŒè¯å¹¶è¡Œç»„çš„æ­¥éª¤åˆ—è¡¨...")
            updated_parallel_groups = list(updated_pipeline.parallel_groups.all())
            for group in updated_parallel_groups:
                print(f"  - å¹¶è¡Œç»„ {group.name} (ID: {group.id}) - steps: {group.steps}")
                
                # æ£€æŸ¥æ­¥éª¤åˆ—è¡¨æ˜¯å¦æ­£ç¡®
                if group.steps:
                    assigned_steps = [step for step in updated_steps if step.parallel_group == group.id]
                    print(f"    å®é™…åˆ†é…åˆ°è¯¥ç»„çš„æ­¥éª¤: {[s.name for s in assigned_steps]}")
            
            # 10. æ€»ç»“ç»“æœ
            print("\nğŸ“Š ä¿å­˜ç»“æœæ€»ç»“:")
            successful_assignments = [step for step in updated_steps if step.parallel_group]
            print(f"âœ… æˆåŠŸåˆ†é…åˆ°å¹¶è¡Œç»„çš„æ­¥éª¤: {len(successful_assignments)}")
            
            if successful_assignments:
                print("ğŸ‰ å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿å­˜æˆåŠŸï¼")
                return True
            else:
                print("âŒ å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿å­˜å¤±è´¥ï¼")
                return False
                
        else:
            print("âŒ æ•°æ®éªŒè¯å¤±è´¥:")
            print(json.dumps(serializer.errors, indent=2, ensure_ascii=False))
            return False
            
    except Exception as e:
        print(f"âŒ è°ƒè¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_model_fields():
    """æ£€æŸ¥æ¨¡å‹å­—æ®µå®šä¹‰"""
    print("\nğŸ” æ£€æŸ¥æ¨¡å‹å­—æ®µå®šä¹‰...")
    
    # æ£€æŸ¥ PipelineStep æ¨¡å‹
    from pipelines.models import PipelineStep
    
    print("ğŸ“‹ PipelineStep æ¨¡å‹å­—æ®µ:")
    for field in PipelineStep._meta.fields:
        if field.name == 'parallel_group':
            print(f"  - {field.name}: {field.__class__.__name__} (max_length: {getattr(field, 'max_length', 'N/A')}, blank: {field.blank}, null: {field.null})")
        elif 'parallel' in field.name.lower():
            print(f"  - {field.name}: {field.__class__.__name__}")
    
    # æ£€æŸ¥ ParallelGroup æ¨¡å‹
    from pipelines.models import ParallelGroup
    
    print("\nğŸ”— ParallelGroup æ¨¡å‹å­—æ®µ:")
    for field in ParallelGroup._meta.fields:
        print(f"  - {field.name}: {field.__class__.__name__}")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨å¹¶è¡Œç»„æ­¥éª¤å…³è”ä¿å­˜è¯¦ç»†è°ƒè¯•...")
    
    # æ£€æŸ¥æ¨¡å‹å­—æ®µ
    check_model_fields()
    
    # æ‰§è¡Œè°ƒè¯•
    success = debug_pipeline_save_process()
    
    if success:
        print("\nğŸ‰ è°ƒè¯•å®Œæˆï¼šå¹¶è¡Œç»„æ­¥éª¤å…³è”åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
    else:
        print("\nâŒ è°ƒè¯•å®Œæˆï¼šå‘ç°é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚")
