#!/usr/bin/env python3
"""
æ¨¡æ‹Ÿå‰ç«¯é¡µé¢è°ƒç”¨ï¼Œæµ‹è¯•å®Œæ•´çš„å¹¶è¡Œç»„åŠŸèƒ½
"""

import subprocess
import json
import sys

def test_frontend_workflow():
    """æ¨¡æ‹Ÿå‰ç«¯å·¥ä½œæµ"""
    print("ğŸ” æ¨¡æ‹Ÿå‰ç«¯é¡µé¢å¹¶è¡Œç»„è·å–å·¥ä½œæµ")
    print("=" * 50)
    
    pipeline_id = 2
    
    # Step 1: å‰ç«¯é¦–å…ˆè°ƒç”¨å¹¶è¡Œç»„APIè·å–å¹¶è¡Œç»„æ•°æ®
    print("\nğŸ“‹ æ­¥éª¤1: è·å–å¹¶è¡Œç»„æ•°æ®")
    cmd1 = [
        'curl', '-s', 
        f'http://localhost:8000/api/v1/pipelines/parallel-groups/?pipeline={pipeline_id}',
        '-H', 'Authorization: Bearer dummy_token_for_test'  # æ¨¡æ‹Ÿè®¤è¯
    ]
    
    # ç”±äºéœ€è¦è®¤è¯ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨Django shellæ¨¡æ‹ŸAPIè°ƒç”¨
    django_cmd = f'''
import sys
sys.path.append('/Users/creed/Workspace/OpenSource/ansflow/backend/django_service')
import os
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ansflow.settings')
import django
django.setup()

from pipelines.models import Pipeline

pipeline = Pipeline.objects.get(id={pipeline_id})
steps = pipeline.steps.all().order_by('order')

# åˆ†æå¹¶è¡Œç»„ (æ¨¡æ‹ŸAPIé€»è¾‘)
parallel_groups = {{}}
for step in steps:
    if step.parallel_group:
        group_name = step.parallel_group
        if group_name not in parallel_groups:
            parallel_groups[group_name] = {{
                'id': group_name,
                'name': group_name,
                'steps': []
            }}
        parallel_groups[group_name]['steps'].append({{
            'id': step.id,
            'name': step.name,
            'step_type': step.step_type,
            'order': step.order
        }})

groups_list = list(parallel_groups.values())
result = {{
    'parallel_groups': groups_list,
    'total_groups': len(groups_list),
    'total_steps': len(steps)
}}

import json
print("PARALLEL_GROUPS_RESULT:")
print(json.dumps(result, indent=2))
'''
    
    try:
        result1 = subprocess.run([
            'python3', '-c', django_cmd
        ], capture_output=True, text=True, check=True)
        
        # æå–ç»“æœ
        output_lines = result1.stdout.split('\n')
        json_start = -1
        for i, line in enumerate(output_lines):
            if line.strip() == "PARALLEL_GROUPS_RESULT:":
                json_start = i + 1
                break
        
        if json_start != -1:
            json_str = '\n'.join(output_lines[json_start:])
            parallel_data = json.loads(json_str)
            
            print("âœ… å¹¶è¡Œç»„æ•°æ®è·å–æˆåŠŸ:")
            print(f"  æ€»æ­¥éª¤æ•°: {parallel_data['total_steps']}")
            print(f"  å¹¶è¡Œç»„æ•°: {parallel_data['total_groups']}")
            
            for group in parallel_data['parallel_groups']:
                print(f"  å¹¶è¡Œç»„: {group['name']}")
                for step in group['steps']:
                    print(f"    - {step['name']} (order: {step['order']})")
        else:
            print("âŒ æ— æ³•è§£æå¹¶è¡Œç»„æ•°æ®")
            return False
            
    except Exception as e:
        print(f"âŒ æ­¥éª¤1å¤±è´¥: {e}")
        return False
    
    # Step 2: å‰ç«¯è°ƒç”¨Jenkins Pipelineé¢„è§ˆAPIç”ŸæˆJenkinsä»£ç 
    print("\nğŸ“‹ æ­¥éª¤2: ç”ŸæˆJenkins Pipeline")
    cmd2 = [
        'curl', '-s', '-X', 'POST',
        'http://localhost:8000/api/v1/cicd/pipelines/preview/',
        '-H', 'Content-Type: application/json',
        '-d', json.dumps({
            "pipeline_id": pipeline_id,
            "preview_mode": False,
            "execution_mode": "remote"
        })
    ]
    
    try:
        result2 = subprocess.run(cmd2, capture_output=True, text=True, check=True)
        preview_data = json.loads(result2.stdout)
        
        workflow_summary = preview_data.get('workflow_summary', {})
        jenkinsfile = preview_data.get('jenkinsfile', '')
        
        print("âœ… Jenkins Pipelineç”ŸæˆæˆåŠŸ:")
        print(f"  æ€»æ­¥éª¤æ•°: {workflow_summary.get('total_steps', 0)}")
        print(f"  æ•°æ®æº: {workflow_summary.get('data_source', 'unknown')}")
        
        # æ£€æŸ¥å¹¶è¡Œè¯­æ³•
        has_parallel = 'parallel {' in jenkinsfile
        parallel_count = jenkinsfile.count('parallel {')
        
        print(f"  åŒ…å«å¹¶è¡Œè¯­æ³•: {'âœ… æ˜¯' if has_parallel else 'âŒ å¦'}")
        print(f"  å¹¶è¡Œç»„æ•°é‡: {parallel_count}")
        
        if has_parallel:
            print("  ğŸ“‹ Jenkins Pipelineç»“æ„:")
            # æå–stageåç§°
            import re
            stages = re.findall(r"stage\\('([^']+)'\\)", jenkinsfile)
            for stage in stages:
                if 'parallel_group_' in stage:
                    print(f"    ğŸ”„ {stage} (å¹¶è¡Œç»„)")
                else:
                    print(f"    â¡ï¸ {stage} (é¡ºåº)")
        
        return has_parallel and parallel_count > 0
        
    except Exception as e:
        print(f"âŒ æ­¥éª¤2å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª å‰ç«¯å¹¶è¡Œç»„åŠŸèƒ½å®Œæ•´æµ‹è¯•")
    print("=" * 60)
    
    success = test_frontend_workflow()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ å‰ç«¯å¹¶è¡Œç»„åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼")
        print("âœ… å‰ç«¯èƒ½æ­£ç¡®è·å–å¹¶è¡Œç»„æ•°æ®")
        print("âœ… Jenkins Pipelineèƒ½æ­£ç¡®ç”Ÿæˆå¹¶è¡Œè¯­æ³•")
        print("âœ… ç«¯åˆ°ç«¯å·¥ä½œæµæ­£å¸¸")
        return 0
    else:
        print("âŒ å‰ç«¯å¹¶è¡Œç»„åŠŸèƒ½ä»æœ‰é—®é¢˜")
        return 1

if __name__ == "__main__":
    sys.exit(main())
