#!/usr/bin/env python3
"""
AnsFlow æ—¥å¿—ä¿®å¤éªŒè¯è„šæœ¬
éªŒè¯FastAPIæ—¥å¿—Redisé›†æˆå’Œå†å²æ—¥å¿—åŒæ­¥æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import sys
import os
from pathlib import Path
from datetime import datetime
import logging
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'backend' / 'django_service'))

# è®¾ç½®Djangoç¯å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ansflow.settings')
import django
django.setup()

from common.unified_log_connector import UnifiedLogConnector, LogEntry, get_config_from_db


class LogFixValidation:
    """æ—¥å¿—ä¿®å¤éªŒè¯ç±»"""
    
    def __init__(self):
        self.config = get_config_from_db()
        self.connector = None
        
    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥å™¨"""
        self.connector = UnifiedLogConnector(self.config)
        await self.connector.initialize()
        print("âœ… ç»Ÿä¸€æ—¥å¿—è¿æ¥å™¨åˆå§‹åŒ–å®Œæˆ")
        
    async def test_fastapi_redis_integration(self):
        """æµ‹è¯•FastAPI Redisé›†æˆ"""
        print("\nğŸ” æµ‹è¯•FastAPI Redisé›†æˆ...")
        
        try:
            # æ¨¡æ‹ŸFastAPIæ—¥å¿—å†™å…¥
            test_log = LogEntry(
                id=f"fastapi-test-{int(datetime.now().timestamp() * 1000)}",
                timestamp=datetime.now().replace(tzinfo=datetime.now().astimezone().tzinfo),
                level='INFO',
                service='fastapi',
                component='test',
                module='validation',
                message='FastAPI Redisé›†æˆæµ‹è¯•æ—¥å¿—',
                execution_id=9999
            )
            
            # å†™å…¥Redis Stream
            message_id = await self.connector.write_realtime_log(test_log)
            print(f"âœ… FastAPIæµ‹è¯•æ—¥å¿—å†™å…¥Redis StreamæˆåŠŸ: {message_id}")
            
            # éªŒè¯èƒ½å¦ä»Streamä¸­è¯»å–
            messages = await self.connector.redis_client.xrevrange(
                'ansflow:logs:stream', 
                count=10
            )
            
            fastapi_logs = [
                msg for msg in messages 
                if msg[1].get('service') == 'fastapi'
            ]
            
            print(f"âœ… Redis Streamä¸­FastAPIæ—¥å¿—æ•°é‡: {len(fastapi_logs)}")
            
            return len(fastapi_logs) > 0
            
        except Exception as e:
            print(f"âŒ FastAPI Redisé›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
            
    async def test_historical_sync(self):
        """æµ‹è¯•å†å²æ—¥å¿—åŒæ­¥"""
        print("\nğŸ” æµ‹è¯•å†å²æ—¥å¿—åŒæ­¥...")
        
        try:
            # æŸ¥è¯¢å†å²æ—¥å¿—æ€»æ•°
            historical_logs = await self.connector.query_historical_logs(limit=1000)
            total_count = len(historical_logs)
            print(f"ğŸ“Š å†å²æ—¥å¿—æ€»æ•°: {total_count}")
            
            # æŒ‰æœåŠ¡åˆ†ç»„ç»Ÿè®¡
            service_stats = {}
            for log in historical_logs:
                service = log.service
                service_stats[service] = service_stats.get(service, 0) + 1
                
            print("ğŸ“ˆ æŒ‰æœåŠ¡åˆ†ç»„ç»Ÿè®¡:")
            for service, count in service_stats.items():
                print(f"   {service}: {count} æ¡æ—¥å¿—")
                
            # æ£€æŸ¥æ˜¯å¦æœ‰FastAPIå†å²æ—¥å¿—
            fastapi_historical = await self.connector.query_historical_logs(
                service='fastapi', 
                limit=100
            )
            
            print(f"âœ… FastAPIå†å²æ—¥å¿—æ•°é‡: {len(fastapi_historical)}")
            
            return total_count > 24  # åº”è¯¥è¶…è¿‡åŸæ¥çš„24æ¡æµ‹è¯•æ•°æ®
            
        except Exception as e:
            print(f"âŒ å†å²æ—¥å¿—åŒæ­¥æµ‹è¯•å¤±è´¥: {e}")
            return False
            
    async def test_realtime_stream(self):
        """æµ‹è¯•å®æ—¶æ—¥å¿—æµ"""
        print("\nğŸ” æµ‹è¯•å®æ—¶æ—¥å¿—æµ...")
        
        try:
            # è·å–æœ€è¿‘çš„å®æ—¶æ—¥å¿—
            messages = await self.connector.redis_client.xrevrange(
                'ansflow:logs:stream',
                count=20
            )
            
            print(f"ğŸ“¡ Redis Streamä¸­æ—¥å¿—æ€»æ•°: {len(messages)}")
            
            # æŒ‰æœåŠ¡åˆ†ç»„
            service_counts = {}
            for msg_id, fields in messages:
                service = fields.get('service', 'unknown')
                service_counts[service] = service_counts.get(service, 0) + 1
                
            print("ğŸ“Š å®æ—¶æ—¥å¿—æŒ‰æœåŠ¡åˆ†ç»„:")
            for service, count in service_counts.items():
                print(f"   {service}: {count} æ¡")
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰é¢„æœŸæœåŠ¡
            expected_services = ['django_service', 'fastapi', 'system']
            has_all_services = all(service in service_counts for service in expected_services)
            
            if has_all_services:
                print("âœ… å®æ—¶æ—¥å¿—æµåŒ…å«æ‰€æœ‰é¢„æœŸæœåŠ¡")
            else:
                missing = [s for s in expected_services if s not in service_counts]
                print(f"âš ï¸  ç¼ºå°‘æœåŠ¡çš„æ—¥å¿—: {missing}")
                
            return len(messages) > 0
            
        except Exception as e:
            print(f"âŒ å®æ—¶æ—¥å¿—æµæµ‹è¯•å¤±è´¥: {e}")
            return False
            
    async def test_data_consistency(self):
        """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§"""
        print("\nğŸ” æµ‹è¯•æ•°æ®ä¸€è‡´æ€§...")
        
        try:
            # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ—¥å¿—å¹¶åŒæ­¥åˆ°æ‰€æœ‰å­˜å‚¨
            test_log = LogEntry(
                id=f"consistency-test-{int(datetime.now().timestamp() * 1000)}",
                timestamp=datetime.now().replace(tzinfo=datetime.now().astimezone().tzinfo),
                level='INFO',
                service='test-validation',
                component='consistency',
                module='validation',
                message='æ•°æ®ä¸€è‡´æ€§æµ‹è¯•æ—¥å¿—'
            )
            
            # åŒæ­¥åˆ°æ‰€æœ‰å­˜å‚¨ç³»ç»Ÿ
            await self.connector.sync_log_entry(test_log)
            print("âœ… æ—¥å¿—å·²åŒæ­¥åˆ°æ‰€æœ‰å­˜å‚¨ç³»ç»Ÿ")
            
            # ç­‰å¾…ä¸€ç§’ç¡®ä¿æ•°æ®å†™å…¥
            await asyncio.sleep(1)
            
            # éªŒè¯ä¸€è‡´æ€§
            consistency = await self.connector.verify_data_consistency(test_log.id)
            print(f"ğŸ“‹ ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ: {consistency}")
            
            return consistency['redis_stream'] and consistency['mysql_historical']
            
        except Exception as e:
            print(f"âŒ æ•°æ®ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {e}")
            return False
            
    async def generate_summary_report(self):
        """ç”Ÿæˆä¿®å¤æ€»ç»“æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆä¿®å¤æ€»ç»“æŠ¥å‘Š...")
        
        try:
            # Redis Streamç»Ÿè®¡
            stream_messages = await self.connector.redis_client.xlen('ansflow:logs:stream')
            
            # å†å²æ—¥å¿—ç»Ÿè®¡
            historical_logs = await self.connector.query_historical_logs(limit=5000)
            historical_count = len(historical_logs)
            
            # æŒ‰æœåŠ¡å’Œæ—¶é—´ç»Ÿè®¡
            service_stats = {}
            recent_24h_count = 0
            now = datetime.now()
            
            for log in historical_logs:
                service = log.service
                service_stats[service] = service_stats.get(service, 0) + 1
                
                # è®¡ç®—24å°æ—¶å†…çš„æ—¥å¿—
                time_diff = now - log.timestamp
                if time_diff.total_seconds() < 24 * 3600:
                    recent_24h_count += 1
                    
            report = {
                'timestamp': datetime.now().isoformat(),
                'redis_stream': {
                    'total_messages': stream_messages,
                    'status': 'æ­£å¸¸' if stream_messages > 0 else 'å¼‚å¸¸'
                },
                'historical_logs': {
                    'total_count': historical_count,
                    'recent_24h': recent_24h_count,
                    'service_distribution': service_stats,
                    'status': 'æ­£å¸¸' if historical_count > 50 else 'æ•°æ®è¾ƒå°‘'
                },
                'data_consistency': {
                    'redis_mysql_sync': 'å·²å»ºç«‹' if historical_count > 24 else 'å¾…å®Œå–„',
                    'fastapi_integration': 'FastAPI' in service_stats,
                    'django_integration': 'django_service' in service_stats
                }
            }
            
            print("\n" + "="*60)
            print("ğŸ“Š ANSFLOW ç»Ÿä¸€æ—¥å¿—ä¿®å¤æ€»ç»“æŠ¥å‘Š")
            print("="*60)
            print(f"ç”Ÿæˆæ—¶é—´: {report['timestamp']}")
            print(f"\nğŸ”„ Redis StreamçŠ¶æ€: {report['redis_stream']['status']}")
            print(f"   æ¶ˆæ¯æ€»æ•°: {report['redis_stream']['total_messages']}")
            print(f"\nğŸ’¾ å†å²æ—¥å¿—çŠ¶æ€: {report['historical_logs']['status']}")
            print(f"   æ€»è®°å½•æ•°: {report['historical_logs']['total_count']}")
            print(f"   24å°æ—¶å†…: {report['historical_logs']['recent_24h']}")
            print(f"\nğŸ“ˆ æœåŠ¡åˆ†å¸ƒ:")
            for service, count in service_stats.items():
                print(f"   {service}: {count} æ¡")
            print(f"\nğŸ”— æ•°æ®ä¸€è‡´æ€§:")
            print(f"   Redis-MySQLåŒæ­¥: {report['data_consistency']['redis_mysql_sync']}")
            print(f"   FastAPIé›†æˆ: {'âœ…' if report['data_consistency']['fastapi_integration'] else 'âŒ'}")
            print(f"   Djangoé›†æˆ: {'âœ…' if report['data_consistency']['django_integration'] else 'âŒ'}")
            print("="*60)
            
            return report
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return None
            
    async def run_validation(self):
        """è¿è¡Œæ‰€æœ‰éªŒè¯æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹AnsFlowæ—¥å¿—ä¿®å¤éªŒè¯...\n")
        
        await self.initialize()
        
        results = {
            'fastapi_redis': await self.test_fastapi_redis_integration(),
            'historical_sync': await self.test_historical_sync(),
            'realtime_stream': await self.test_realtime_stream(),
            'data_consistency': await self.test_data_consistency()
        }
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        report = await self.generate_summary_report()
        
        # æ€»ç»“éªŒè¯ç»“æœ
        print(f"\nğŸ éªŒè¯å®Œæˆï¼")
        print("æµ‹è¯•ç»“æœ:")
        for test_name, passed in results.items():
            status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
            print(f"   {test_name}: {status}")
            
        overall_success = all(results.values())
        if overall_success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ—¥å¿—ä¿®å¤æˆåŠŸã€‚")
        else:
            failed_tests = [name for name, passed in results.items() if not passed]
            print(f"\nâš ï¸  ä»¥ä¸‹æµ‹è¯•å¤±è´¥: {', '.join(failed_tests)}")
            
        return overall_success, report
        
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.connector:
            await self.connector.close()


async def main():
    """ä¸»å‡½æ•°"""
    validator = LogFixValidation()
    try:
        success, report = await validator.run_validation()
        return 0 if success else 1
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {e}")
        return 1
    finally:
        await validator.close()


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
