"""
Djangoæ•°æ®åº“è¿æ¥æœåŠ¡
ç”¨äºä»FastAPIè¿æ¥åˆ°Djangoçš„MySQLæ•°æ®åº“è·å–çœŸå®çš„æ‰§è¡Œæ•°æ®
"""
import asyncio
import aiomysql
import structlog
import os
from typing import Dict, List, Optional
from datetime import datetime

logger = structlog.get_logger(__name__)


class DjangoDBService:
    """Djangoæ•°æ®åº“è¿æ¥æœåŠ¡"""
    
    def __init__(self):
        self.connection_pool = None
        # Djangoæ•°æ®åº“è¿æ¥é…ç½®ï¼ˆMySQLï¼‰
        self.db_config = {
            "host": os.getenv("DJANGO_DB_HOST", "localhost"),
            "port": int(os.getenv("DJANGO_DB_PORT", 3306)),
            "user": os.getenv("DJANGO_DB_USER", "ansflow_user"),
            "password": os.getenv("DJANGO_DB_PASSWORD", "ansflow_password_123"),
            "db": os.getenv("DJANGO_DB_NAME", "ansflow_db"),
            "charset": "utf8mb4",
            "autocommit": True
        }
    
    async def init_connection_pool(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± """
        try:
            self.connection_pool = await aiomysql.create_pool(
                **self.db_config,
                minsize=1,
                maxsize=10
            )
            logger.info("Django MySQL database connection pool initialized")
        except Exception as e:
            logger.error("Failed to initialize MySQL database connection pool", error=str(e))
            # å¦‚æœæ— æ³•è¿æ¥åˆ°æ•°æ®åº“ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            self.connection_pool = None
    
    async def close_connection_pool(self):
        """å…³é—­æ•°æ®åº“è¿æ¥æ± """
        if self.connection_pool:
            self.connection_pool.close()
            await self.connection_pool.wait_closed()
            logger.info("Django MySQL database connection pool closed")
    
    async def get_execution_with_steps(self, execution_id: int) -> Optional[Dict]:
        """è·å–æ‰§è¡Œè®°å½•åŠå…¶æ­¥éª¤ä¿¡æ¯"""
        if not self.connection_pool:
            logger.warning("No database connection available, using mock data", execution_id=execution_id)
            return await self._get_mock_execution_data(execution_id)
        
        try:
            async with self.connection_pool.acquire() as connection:
                async with connection.cursor(aiomysql.DictCursor) as cursor:
                    # æŸ¥è¯¢æ‰§è¡Œè®°å½•
                    await cursor.execute("""
                        SELECT pe.id, pe.status, pe.created_at, pe.started_at, pe.completed_at,
                               pe.logs as execution_logs, pe.parameters,
                               p.name as pipeline_name, p.description as pipeline_description
                        FROM cicd_integrations_pipelineexecution pe
                        LEFT JOIN pipelines_pipeline p ON pe.pipeline_id = p.id
                        WHERE pe.id = %s
                    """, (execution_id,))
                    
                    execution_row = await cursor.fetchone()
                    if not execution_row:
                        logger.warning("Execution not found in database", execution_id=execution_id)
                        return None
                    
                    # æŸ¥è¯¢æ­¥éª¤è®°å½•ï¼ˆåŒ…æ‹¬å¹¶è¡Œç»„ä¿¡æ¯ï¼‰
                    await cursor.execute("""
                        SELECT se.id, se.status, se.started_at, se.completed_at,
                               se.logs, se.error_message, se.order,
                               cas.name as atomic_step_name,
                               ps.parallel_group
                        FROM cicd_integrations_stepexecution se
                        LEFT JOIN cicd_integrations_atomicstep cas ON se.atomic_step_id = cas.id
                        LEFT JOIN pipelines_pipelinestep ps ON (cas.id = ps.id AND cas.pipeline_id = ps.pipeline_id)
                        WHERE se.pipeline_execution_id = %s
                        ORDER BY se.order ASC, se.id ASC
                    """, (execution_id,))
                    
                    step_rows = await cursor.fetchall()
                    
                    # å¤„ç†æ­¥éª¤æ•°æ®ï¼ŒæŒ‰å¹¶è¡Œç»„ç»„ç»‡
                    steps = []
                    parallel_groups = {}
                    
                    for step_row in step_rows:
                        # è®¡ç®—æ‰§è¡Œæ—¶é—´
                        execution_time = None
                        if step_row["started_at"] and step_row["completed_at"]:
                            execution_time = (step_row["completed_at"] - step_row["started_at"]).total_seconds()
                        
                        step_data = {
                            "id": step_row["id"],
                            "name": step_row["atomic_step_name"] or f"æ­¥éª¤ {step_row['id']}",
                            "status": step_row["status"].lower() if step_row["status"] else "pending",
                            "execution_time": execution_time,
                            "output": step_row["logs"] or "",
                            "error_message": step_row["error_message"],
                            "order": step_row["order"],
                            "parallel_group": step_row["parallel_group"]
                        }
                        
                        # å¦‚æœæœ‰å¹¶è¡Œç»„ï¼Œåˆ™æŒ‰ç»„å½’ç±»
                        if step_row["parallel_group"]:
                            if step_row["parallel_group"] not in parallel_groups:
                                parallel_groups[step_row["parallel_group"]] = {
                                    "group_id": step_row["parallel_group"],
                                    "name": f"å¹¶è¡Œç»„ {len(parallel_groups) + 1}",
                                    "type": "parallel_group",
                                    "status": "pending",
                                    "steps": [],
                                    "order": step_row["order"]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ­¥éª¤çš„orderä½œä¸ºç»„çš„order
                                }
                            parallel_groups[step_row["parallel_group"]]["steps"].append(step_data)
                        else:
                            # æ²¡æœ‰å¹¶è¡Œç»„çš„æ­¥éª¤ç›´æ¥æ·»åŠ 
                            steps.append(step_data)
                    
                    # å°†å¹¶è¡Œç»„æ·»åŠ åˆ°æ­¥éª¤åˆ—è¡¨ä¸­ï¼Œå¹¶æŒ‰orderæ’åº
                    for group_id, group_data in parallel_groups.items():
                        # è®¡ç®—å¹¶è¡Œç»„çš„æ•´ä½“çŠ¶æ€
                        group_steps = group_data["steps"]
                        if all(step["status"] == "success" for step in group_steps):
                            group_data["status"] = "success"
                        elif any(step["status"] == "failed" for step in group_steps):
                            group_data["status"] = "failed"
                        elif any(step["status"] == "running" for step in group_steps):
                            group_data["status"] = "running"
                        else:
                            group_data["status"] = "pending"
                        
                        # è®¡ç®—å¹¶è¡Œç»„çš„æ€»æ‰§è¡Œæ—¶é—´ï¼ˆæœ€é•¿çš„æ­¥éª¤æ—¶é—´ï¼‰
                        max_execution_time = 0
                        for step in group_steps:
                            if step["execution_time"]:
                                max_execution_time = max(max_execution_time, step["execution_time"])
                        group_data["execution_time"] = max_execution_time if max_execution_time > 0 else None
                        
                        steps.append(group_data)
                    
                    # æŒ‰orderæ’åºæ‰€æœ‰æ­¥éª¤å’Œç»„
                    steps.sort(key=lambda x: x.get("order", 0))
                    
                    # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
                    total_execution_time = 0
                    if execution_row["started_at"] and execution_row["completed_at"]:
                        total_execution_time = (execution_row["completed_at"] - execution_row["started_at"]).total_seconds()
                    elif execution_row["started_at"]:
                        total_execution_time = (datetime.now() - execution_row["started_at"]).total_seconds()
                    
                    return {
                        "id": execution_row["id"],
                        "status": execution_row["status"].lower() if execution_row["status"] else "pending",
                        "pipeline_name": execution_row["pipeline_name"] or f"æµæ°´çº¿æ‰§è¡Œ #{execution_id}",
                        "execution_time": total_execution_time,
                        "steps": steps,
                        "created_at": execution_row["created_at"].isoformat() if execution_row["created_at"] else None,
                        "started_at": execution_row["started_at"].isoformat() if execution_row["started_at"] else None,
                        "completed_at": execution_row["completed_at"].isoformat() if execution_row["completed_at"] else None
                    }
                    
        except Exception as e:
            logger.error("Error fetching execution data from Django MySQL DB", 
                        execution_id=execution_id, error=str(e))
            # å‡ºé”™æ—¶è¿”å›é™æ€æ¨¡æ‹Ÿæ•°æ®
            return await self._get_mock_execution_data(execution_id)
    
    async def get_execution_logs(self, execution_id: int, last_count: int = 0) -> List[Dict]:
        """è·å–æ‰§è¡Œæ—¥å¿—ï¼ˆå¢é‡è·å–ï¼‰"""
        if not self.connection_pool:
            # å¦‚æœæ²¡æœ‰æ•°æ®åº“è¿æ¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆé¿å…æ¨¡æ‹Ÿæ—¥å¿—ï¼‰
            return []
        
        try:
            async with self.connection_pool.acquire() as connection:
                async with connection.cursor(aiomysql.DictCursor) as cursor:
                    # ä»æ‰§è¡Œè®°å½•å’Œæ­¥éª¤è®°å½•ä¸­æå–æ—¥å¿—ä¿¡æ¯
                    # å…ˆè·å–ä¸»æ‰§è¡Œæ—¥å¿—
                    await cursor.execute("""
                        SELECT pe.id, pe.logs, pe.status, pe.started_at, pe.completed_at,
                               p.name as pipeline_name
                        FROM cicd_integrations_pipelineexecution pe
                        LEFT JOIN pipelines_pipeline p ON pe.pipeline_id = p.id
                        WHERE pe.id = %s
                    """, (execution_id,))
                    
                    execution_row = await cursor.fetchone()
                    if not execution_row:
                        return []
                    
                    # è·å–æ­¥éª¤æ—¥å¿—
                    await cursor.execute("""
                        SELECT se.id, se.logs, se.status, se.started_at, se.completed_at,
                               se.order, atos.name as step_name
                        FROM cicd_integrations_stepexecution se
                        LEFT JOIN cicd_integrations_atomicstep atos ON se.atomic_step_id = atos.id
                        WHERE se.pipeline_execution_id = %s
                        ORDER BY se.order ASC, se.id ASC
                    """, (execution_id,))
                    
                    step_rows = await cursor.fetchall()
                    
                    # æ„å»ºæ—¥å¿—æ¡ç›®
                    logs = []
                    log_id = 1
                    
                    # æ·»åŠ æ‰§è¡Œå¼€å§‹æ—¥å¿—
                    if execution_row["started_at"]:
                        logs.append({
                            "id": log_id,
                            "timestamp": execution_row["started_at"].isoformat(),
                            "level": "info",
                            "message": f"ğŸš€ å¼€å§‹æ‰§è¡Œæµæ°´çº¿: {execution_row['pipeline_name']}",
                            "step_name": None,
                            "source": "pipeline"
                        })
                        log_id += 1
                    
                    # æ·»åŠ æ­¥éª¤æ—¥å¿—
                    for step_row in step_rows:
                        if step_row["started_at"]:
                            logs.append({
                                "id": log_id,
                                "timestamp": step_row["started_at"].isoformat(),
                                "level": "info",
                                "message": f"â³ å¼€å§‹æ‰§è¡Œæ­¥éª¤: {step_row['step_name'] or ('æ­¥éª¤' + str(step_row['id']))}",
                                "step_name": step_row["step_name"],
                                "source": "step"
                            })
                            log_id += 1
                        
                        # æ·»åŠ æ­¥éª¤è¯¦ç»†æ—¥å¿—
                        if step_row["logs"]:
                            log_lines = step_row["logs"].split('\n')
                            for line in log_lines:
                                if line.strip():
                                    logs.append({
                                        "id": log_id,
                                        "timestamp": step_row["started_at"].isoformat() if step_row["started_at"] else datetime.now().isoformat(),
                                        "level": "info",
                                        "message": line,
                                        "step_name": step_row["step_name"],
                                        "source": "step_output"
                                    })
                                    log_id += 1
                        
                        if step_row["completed_at"]:
                            status_emoji = "âœ…" if step_row["status"] == "success" else "âŒ" if step_row["status"] == "failed" else "â¹ï¸"
                            logs.append({
                                "id": log_id,
                                "timestamp": step_row["completed_at"].isoformat(),
                                "level": "success" if step_row["status"] == "success" else "error" if step_row["status"] == "failed" else "info",
                                "message": f"{status_emoji} æ­¥éª¤å®Œæˆ: {step_row['step_name'] or ('æ­¥éª¤' + str(step_row['id']))}",
                                "step_name": step_row["step_name"],
                                "source": "step"
                            })
                            log_id += 1
                    
                    # æ·»åŠ æ‰§è¡Œå®Œæˆæ—¥å¿—
                    if execution_row["completed_at"]:
                        status_emoji = "ğŸ‰" if execution_row["status"] == "success" else "ğŸ’¥" if execution_row["status"] == "failed" else "â¹ï¸"
                        logs.append({
                            "id": log_id,
                            "timestamp": execution_row["completed_at"].isoformat(),
                            "level": "success" if execution_row["status"] == "success" else "error" if execution_row["status"] == "failed" else "info",
                            "message": f"{status_emoji} æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼ŒçŠ¶æ€: {execution_row['status'].upper()}",
                            "step_name": None,
                            "source": "pipeline"
                        })
                    
                    # è¿”å›å¢é‡æ—¥å¿—ï¼ˆä» last_count å¼€å§‹ï¼‰
                    if last_count < len(logs):
                        return logs[last_count:]
                    else:
                        return []
                
        except Exception as e:
            logger.error("Error fetching execution logs from Django DB", 
                        execution_id=execution_id, error=str(e))
            # å‡ºé”™æ—¶è¿”å›ç©ºåˆ—è¡¨
            return []
    
    async def _get_mock_execution_data(self, execution_id: int) -> Dict:
        """è·å–æ¨¡æ‹Ÿæ‰§è¡Œæ•°æ®ï¼ˆå½“æ— æ³•è¿æ¥åˆ°çœŸå®æ•°æ®åº“æ—¶ä½¿ç”¨ï¼‰"""
        logger.warning("Using mock execution data", execution_id=execution_id)
        
        # è¿”å›é™æ€çš„æ¨¡æ‹Ÿæ•°æ®ï¼Œä¸åŸºäºæ—¶é—´å˜åŒ–
        return {
            "id": execution_id,
            "status": "completed",  # å›ºå®šçŠ¶æ€ï¼Œä¸ä¼šåŠ¨æ€å˜åŒ–
            "pipeline_name": f"æµæ°´çº¿æ‰§è¡Œ #{execution_id}",
            "execution_time": 120.5,
            "steps": [
                {
                    "id": 1,
                    "name": "ç¯å¢ƒæ£€æŸ¥",
                    "status": "success",
                    "execution_time": 5.2,
                    "output": "âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ",
                    "error_message": None
                },
                {
                    "id": 2,
                    "name": "ä»£ç æ‹‰å–",
                    "status": "success", 
                    "execution_time": 8.3,
                    "output": "âœ… ä»£ç æ‹‰å–å®Œæˆ",
                    "error_message": None
                },
                {
                    "id": 3,
                    "name": "æ„å»ºåº”ç”¨",
                    "status": "success",
                    "execution_time": 45.8,
                    "output": "âœ… åº”ç”¨æ„å»ºå®Œæˆ",
                    "error_message": None
                },
                {
                    "id": 4,
                    "name": "è¿è¡Œæµ‹è¯•",
                    "status": "success",
                    "execution_time": 32.1,
                    "output": "âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡",
                    "error_message": None
                },
                {
                    "id": 5,
                    "name": "éƒ¨ç½²åº”ç”¨",
                    "status": "success",
                    "execution_time": 29.1,
                    "output": "âœ… éƒ¨ç½²å®Œæˆ",
                    "error_message": None
                }
            ],
            "created_at": "2025-07-14T10:00:00",
            "started_at": "2025-07-14T10:00:05",
            "finished_at": "2025-07-14T10:02:05"
        }


# å…¨å±€æ•°æ®åº“æœåŠ¡å®ä¾‹
django_db_service = DjangoDBService()
