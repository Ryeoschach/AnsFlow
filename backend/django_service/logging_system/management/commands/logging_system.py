import asyncio
import logging
from datetime import datetime
from django.core.management.base import BaseCommand
from django.conf import settings

from logging_system.models import UnifiedLog, LogSyncPosition


class Command(BaseCommand):
    help = 'AnsFlowç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿç®¡ç†å‘½ä»¤ - åˆå§‹åŒ–ã€éªŒè¯ã€åŒæ­¥ç­‰åŠŸèƒ½'

    def add_arguments(self, parser):
        parser.add_argument(
            'action',
            choices=['init', 'sync', 'status', 'clean'],
            help='æ‰§è¡Œçš„æ“ä½œ: init(åˆå§‹åŒ–), sync(åŒæ­¥), status(çŠ¶æ€æ£€æŸ¥), clean(æ¸…ç†)'
        )
        
        parser.add_argument(
            '--days',
            type=int,
            default=30,
            help='æ¸…ç†æ“ä½œä¿ç•™çš„å¤©æ•°(é»˜è®¤30å¤©)'
        )

    def handle(self, *args, **options):
        action = options['action']
        
        try:
            if action == 'init':
                self.init_logging_system()
            elif action == 'sync':
                self.run_sync_once()
            elif action == 'status':
                self.show_status()
            elif action == 'clean':
                self.clean_old_logs(options['days'])
                
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ æ“ä½œå¤±è´¥: {e}')
            )
            return
            
        self.stdout.write(
            self.style.SUCCESS(f'âœ… æ“ä½œ {action} å®Œæˆ')
        )

    def init_logging_system(self):
        """åˆå§‹åŒ–ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ"""
        self.stdout.write("ğŸš€ åˆå§‹åŒ–AnsFlowç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ...")
        
        # æ£€æŸ¥æ•°æ®åº“è¡¨æ˜¯å¦å­˜åœ¨
        try:
            count = UnifiedLog.objects.count()
            self.stdout.write(f"ğŸ“Š å½“å‰å†å²æ—¥å¿—æ•°é‡: {count}")
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ æ•°æ®åº“è¡¨æ£€æŸ¥å¤±è´¥: {e}')
            )
            return
            
        # æ£€æŸ¥Redisè¿æ¥
        try:
            import redis
            from django.conf import settings
            
            # è·å–Redisé…ç½®
            redis_host = getattr(settings, 'REDIS_HOST', 'localhost')
            redis_port = getattr(settings, 'REDIS_PORT', 6379)
            redis_db = getattr(settings, 'REDIS_DB', 5)
            
            r = redis.Redis(host=redis_host, port=redis_port, db=redis_db)
            r.ping()
            
            # æ£€æŸ¥æ—¥å¿—æµé•¿åº¦
            stream_length = r.xlen('ansflow:logs:stream')
            self.stdout.write(f"ğŸ“¡ Redis Streamä¸­æ—¥å¿—æ•°é‡: {stream_length}")
            
        except Exception as e:
            self.stdout.write(
                self.style.WARNING(f'âš ï¸  Redisè¿æ¥æ£€æŸ¥å¤±è´¥: {e}')
            )
            
        self.stdout.write("âœ… ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–æ£€æŸ¥å®Œæˆ")

    def show_status(self):
        """æ˜¾ç¤ºæ—¥å¿—ç³»ç»ŸçŠ¶æ€"""
        self.stdout.write("ğŸ“Š AnsFlowç»Ÿä¸€æ—¥å¿—ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š")
        self.stdout.write("=" * 50)
        
        # å†å²æ—¥å¿—ç»Ÿè®¡
        try:
            total_logs = UnifiedLog.objects.count()
            services = UnifiedLog.objects.values_list('service', flat=True).distinct()
            
            self.stdout.write(f"ğŸ’¾ å†å²æ—¥å¿—æ€»æ•°: {total_logs}")
            self.stdout.write(f"ğŸ”§ æœåŠ¡æ•°é‡: {len(services)}")
            self.stdout.write(f"ğŸ“‹ æœåŠ¡åˆ—è¡¨: {', '.join(services)}")
            
            # æŒ‰æœåŠ¡ç»Ÿè®¡
            from django.db.models import Count
            service_stats = UnifiedLog.objects.values('service').annotate(
                count=Count('id')
            ).order_by('-count')
            
            self.stdout.write("ğŸ“ˆ æŒ‰æœåŠ¡ç»Ÿè®¡:")
            for stat in service_stats:
                self.stdout.write(f"   {stat['service']}: {stat['count']} æ¡")
                
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ å†å²æ—¥å¿—ç»Ÿè®¡å¤±è´¥: {e}')
            )
            
        # Redis StreamçŠ¶æ€
        try:
            import redis
            redis_host = getattr(settings, 'REDIS_HOST', 'localhost')
            redis_port = getattr(settings, 'REDIS_PORT', 6379)
            redis_db = getattr(settings, 'REDIS_DB', 5)
            
            r = redis.Redis(host=redis_host, port=redis_port, db=redis_db)
            stream_length = r.xlen('ansflow:logs:stream')
            
            self.stdout.write(f"ğŸ“¡ Redis Streamé•¿åº¦: {stream_length}")
            
        except Exception as e:
            self.stdout.write(
                self.style.WARNING(f'âš ï¸  Redis StreamçŠ¶æ€è·å–å¤±è´¥: {e}')
            )
            
        # åŒæ­¥ä½ç½®çŠ¶æ€
        try:
            sync_positions = LogSyncPosition.objects.all()
            if sync_positions:
                self.stdout.write("ğŸ”„ åŒæ­¥ä½ç½®çŠ¶æ€:")
                for pos in sync_positions:
                    self.stdout.write(f"   {pos.service_name}: {pos.redis_stream_id}")
            else:
                self.stdout.write("âš ï¸  æ— åŒæ­¥ä½ç½®è®°å½•")
                
        except Exception as e:
            self.stdout.write(
                self.style.WARNING(f'âš ï¸  åŒæ­¥ä½ç½®çŠ¶æ€è·å–å¤±è´¥: {e}')
            )

    def run_sync_once(self):
        """æ‰§è¡Œä¸€æ¬¡æ—¥å¿—åŒæ­¥"""
        self.stdout.write("ğŸ”„ å¼€å§‹æ‰§è¡Œæ—¥å¿—åŒæ­¥...")
        
        try:
            # å¯¼å…¥åŒæ­¥æ¨¡å—
            import sys
            from pathlib import Path
            
            # æ·»åŠ commonè·¯å¾„
            common_path = Path(__file__).parent.parent.parent.parent.parent.parent / 'common'
            sys.path.insert(0, str(common_path))
            
            from log_sync_service import LogSyncService
            
            # è¿è¡ŒåŒæ­¥
            async def sync_once():
                service = LogSyncService()
                try:
                    await service.initialize()
                    synced_count = await service.sync_logs_to_mysql()
                    return synced_count
                finally:
                    await service.close()
            
            synced_count = asyncio.run(sync_once())
            self.stdout.write(f"âœ… åŒæ­¥å®Œæˆï¼Œå¤„ç†äº† {synced_count} æ¡æ—¥å¿—")
            
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ åŒæ­¥å¤±è´¥: {e}')
            )

    def clean_old_logs(self, days):
        """æ¸…ç†æ—§æ—¥å¿—"""
        from datetime import timedelta
        from django.utils import timezone
        
        cutoff_date = timezone.now() - timedelta(days=days)
        
        self.stdout.write(f"ğŸ§¹ æ¸…ç† {days} å¤©å‰çš„æ—¥å¿— (åœ¨{cutoff_date.strftime('%Y-%m-%d %H:%M:%S')}ä¹‹å‰)")
        
        try:
            deleted_count, _ = UnifiedLog.objects.filter(
                timestamp__lt=cutoff_date
            ).delete()
            
            self.stdout.write(f"âœ… å·²æ¸…ç† {deleted_count} æ¡å†å²æ—¥å¿—")
            
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ æ¸…ç†å¤±è´¥: {e}')
            )
