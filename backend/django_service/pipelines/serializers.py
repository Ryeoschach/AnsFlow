from rest_framework import serializers
from .models import (
    Pipeline, PipelineStep, PipelineRun, PipelineToolMapping,
    ParallelGroup, ApprovalRequest, WorkflowExecution, StepExecutionHistory
)
from cicd_integrations.models import AtomicStep


class PipelineStepSerializer(serializers.ModelSerializer):
    # Ansibleå…³è”å­—æ®µ
    ansible_playbook_name = serializers.CharField(source='ansible_playbook.name', read_only=True)
    ansible_inventory_name = serializers.CharField(source='ansible_inventory.name', read_only=True)
    ansible_credential_name = serializers.CharField(source='ansible_credential.name', read_only=True)
    
    class Meta:
        model = PipelineStep
        fields = [
            'id', 'name', 'description', 'status', 'step_type',
            'command', 'environment_vars', 'timeout_seconds', 'order',
            'ansible_playbook', 'ansible_playbook_name',
            'ansible_inventory', 'ansible_inventory_name', 
            'ansible_credential', 'ansible_credential_name',
            'ansible_parameters',
            # é«˜çº§å·¥ä½œæµåŠŸèƒ½å­—æ®µ
            'dependencies', 'parallel_group', 'conditions',
            'approval_required', 'approval_users', 'approval_status',
            'approved_by', 'approved_at', 'retry_policy', 'notification_config',
            'output_log', 'error_log', 'exit_code',
            'started_at', 'completed_at'
        ]
        read_only_fields = ['id', 'output_log', 'error_log', 'exit_code', 'started_at', 'completed_at',
                           'approval_status', 'approved_by', 'approved_at']


class AtomicStepInPipelineSerializer(serializers.ModelSerializer):
    """AtomicStepåºåˆ—åŒ–å™¨ï¼Œç”¨äºPipelineä¸­çš„stepså­—æ®µ"""
    class Meta:
        model = AtomicStep
        fields = [
            'id', 'name', 'step_type', 'description', 'order',
            'parameters', 'is_active', 'created_at'
        ]
        read_only_fields = ['id', 'created_at']


class PipelineRunSerializer(serializers.ModelSerializer):
    class Meta:
        model = PipelineRun
        fields = [
            'id', 'run_number', 'status', 'triggered_by', 'trigger_type',
            'trigger_data', 'started_at', 'completed_at', 'created_at', 'artifacts'
        ]
        read_only_fields = ['id', 'run_number', 'triggered_by', 'started_at', 'completed_at', 'created_at']


class PipelineSerializer(serializers.ModelSerializer):
    # å°†stepså­—æ®µæ”¹ä¸ºå¯å†™å­—æ®µï¼Œæ—¢èƒ½è¯»å–åˆèƒ½å†™å…¥
    steps = serializers.JSONField(required=False, allow_null=True, default=list)
    atomic_steps = AtomicStepInPipelineSerializer(many=True, read_only=True)  # å…¼å®¹å­—æ®µ
    runs = PipelineRunSerializer(many=True, read_only=True)
    project_name = serializers.CharField(source='project.name', read_only=True)
    created_by_username = serializers.CharField(source='created_by.username', read_only=True)
    
    # æ–°å¢ï¼šå·¥å…·å…³è”å­—æ®µ
    execution_tool_name = serializers.CharField(source='execution_tool.name', read_only=True)
    execution_tool_type = serializers.CharField(source='execution_tool.tool_type', read_only=True)
    
    class Meta:
        model = Pipeline
        fields = [
            'id', 'name', 'description', 'status', 'is_active', 'config',
            'project', 'project_name', 'created_by', 'created_by_username',
            'created_at', 'updated_at', 'started_at', 'completed_at',
            # æ–°å¢å­—æ®µ
            'execution_tool', 'execution_tool_name', 'execution_tool_type',
            'tool_job_name', 'tool_job_config', 'execution_mode',
            'steps', 'atomic_steps', 'runs'  # åŒ…å«åˆå¹¶çš„stepså’Œå…¼å®¹çš„atomic_steps
        ]
        read_only_fields = ['id', 'created_by', 'created_at', 'updated_at', 'started_at', 'completed_at']
    
    def to_representation(self, instance):
        """è‡ªå®šä¹‰åºåˆ—åŒ–è¾“å‡ºï¼Œåˆå¹¶è¿”å›PipelineStepå’ŒAtomicStepæ•°æ®"""
        data = super().to_representation(instance)
        
        # é¦–å…ˆå°è¯•è·å–PipelineStep
        pipeline_steps = instance.steps.all().order_by('order')
        if pipeline_steps.exists():
            data['steps'] = PipelineStepSerializer(pipeline_steps, many=True).data
        else:
            # å¦‚æœæ²¡æœ‰PipelineStepï¼Œè¿”å›AtomicStepæ•°æ®ï¼ˆè½¬æ¢ä¸ºå…¼å®¹æ ¼å¼ï¼‰
            atomic_steps = instance.atomic_steps.all().order_by('order')
            if atomic_steps.exists():
                # å°†AtomicStepè½¬æ¢ä¸ºPipelineStepå…¼å®¹æ ¼å¼
                steps_data = []
                for atomic_step in atomic_steps:
                    step_data = {
                        'id': atomic_step.id,
                        'name': atomic_step.name,
                        'description': atomic_step.description,
                        'step_type': atomic_step.step_type,
                        'order': atomic_step.order,
                        'status': 'pending',  # é»˜è®¤çŠ¶æ€
                        'ansible_parameters': atomic_step.parameters,
                        # ä»parametersä¸­æå–ansibleå­—æ®µ
                        'ansible_playbook': atomic_step.ansible_playbook_id if atomic_step.ansible_playbook else None,
                        'ansible_inventory': atomic_step.ansible_inventory_id if atomic_step.ansible_inventory else None,
                        'ansible_credential': atomic_step.ansible_credential_id if atomic_step.ansible_credential else None,
                    }
                    steps_data.append(step_data)
                data['steps'] = steps_data
            else:
                data['steps'] = []
        
        return data

    def create(self, validated_data):
        validated_data['created_by'] = self.context['request'].user
        steps_data = validated_data.pop('steps', [])
        pipeline = super().create(validated_data)
        
        # åˆ›å»ºå…³è”çš„Pipelineæ­¥éª¤
        self._create_pipeline_steps(pipeline, steps_data)
        
        return pipeline
    
    def update(self, instance, validated_data):
        # æ£€æŸ¥åŸå§‹æ•°æ®ä¸­æ˜¯å¦åŒ…å«stepså­—æ®µ
        request_data = getattr(self.context.get('request'), 'data', {})
        has_steps_field = 'steps' in request_data
        
        steps_data = validated_data.pop('steps', None)
        instance = super().update(instance, validated_data)
        
        # åªæœ‰å½“è¯·æ±‚ä¸­æ˜ç¡®åŒ…å«stepså­—æ®µæ—¶æ‰æ›´æ–°æ­¥éª¤
        if has_steps_field and steps_data is not None:
            # åˆ é™¤ç°æœ‰çš„Pipelineæ­¥éª¤
            instance.steps.all().delete()
            
            # åŒæ—¶åˆ é™¤ç°æœ‰çš„AtomicStepï¼ˆè¿™æ˜¯å…³é”®ä¿®å¤ï¼‰
            instance.atomic_steps.all().delete()
            
            # åˆ›å»ºæ–°çš„Pipelineæ­¥éª¤å’ŒAtomicStep
            self._create_pipeline_steps(instance, steps_data)
        
        return instance
    
    def _create_pipeline_steps(self, pipeline, steps_data):
        """åˆ›å»ºPipelineæ­¥éª¤çš„è¾…åŠ©æ–¹æ³• - åŒæ—¶åˆ›å»ºPipelineStepå’ŒAtomicStep"""
        for step_data in steps_data:
            try:
                # åˆ›å»ºAtomicStepï¼ˆè¿™æ˜¯é¢„è§ˆAPIä½¿ç”¨çš„æ•°æ®æºï¼‰
                atomic_step_data = {
                    'pipeline': pipeline,
                    'name': step_data.get('name', ''),
                    'description': step_data.get('description', ''),
                    'step_type': step_data.get('step_type', 'custom'),
                    'order': step_data.get('order', 0),
                    'parameters': step_data.get('parameters', {}),
                    'is_active': True,
                    'created_by': pipeline.created_by,
                }
                
                # å¤„ç†Ansibleç›¸å…³å­—æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰
                parameters = step_data.get('parameters', {})
                if step_data.get('step_type') == 'ansible':
                    playbook_id = parameters.get('playbook_id')
                    inventory_id = parameters.get('inventory_id')
                    credential_id = parameters.get('credential_id')
                    
                    if playbook_id:
                        atomic_step_data['ansible_playbook_id'] = playbook_id
                    if inventory_id:
                        atomic_step_data['ansible_inventory_id'] = inventory_id
                    if credential_id:
                        atomic_step_data['ansible_credential_id'] = credential_id
                
                print(f"Creating AtomicStep with data: {atomic_step_data}")
                created_atomic_step = AtomicStep.objects.create(**atomic_step_data)
                print(f"Successfully created AtomicStep: {created_atomic_step.id} - {created_atomic_step.name}")
                
                # åŒæ—¶åˆ›å»ºPipelineStepï¼ˆä¸ºäº†å‘åå…¼å®¹ï¼‰
                pipeline_step_data = {
                    'pipeline': pipeline,
                    'name': step_data.get('name', ''),
                    'description': step_data.get('description', ''),
                    'step_type': self._map_step_type(step_data.get('step_type', 'custom')),
                    'order': step_data.get('order', 0),
                    'status': 'pending',  # é»˜è®¤çŠ¶æ€
                    'ansible_parameters': step_data.get('parameters', {}),
                    # å…³é”®ä¿®å¤ï¼šå¤„ç†å¹¶è¡Œç»„å­—æ®µ
                    'parallel_group': step_data.get('parallel_group', ''),
                    # å…³é”®ä¿®å¤ï¼šä»parametersä¸­æå–commandå­—æ®µ
                    'command': parameters.get('command', ''),
                }
                
                # å¤„ç†Ansibleç›¸å…³å­—æ®µ
                if step_data.get('step_type') == 'ansible':
                    playbook_id = parameters.get('playbook_id')
                    inventory_id = parameters.get('inventory_id')
                    credential_id = parameters.get('credential_id')
                    
                    if playbook_id:
                        pipeline_step_data['ansible_playbook_id'] = playbook_id
                    if inventory_id:
                        pipeline_step_data['ansible_inventory_id'] = inventory_id
                    if credential_id:
                        pipeline_step_data['ansible_credential_id'] = credential_id
                
                # å¤„ç†Gitå‡­æ®
                if step_data.get('git_credential'):
                    # Gitå‡­æ®å­˜å‚¨åœ¨parametersä¸­
                    pipeline_step_data['ansible_parameters']['git_credential_id'] = step_data['git_credential']
                
                # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºå¹¶è¡Œç»„å­—æ®µ
                if step_data.get('parallel_group'):
                    print(f"ğŸ”— æ­¥éª¤ '{step_data.get('name')}' åˆ†é…åˆ°å¹¶è¡Œç»„: {step_data.get('parallel_group')}")
                
                print(f"Creating PipelineStep with data: {pipeline_step_data}")
                created_step = PipelineStep.objects.create(**pipeline_step_data)
                print(f"Successfully created PipelineStep: {created_step.id} - {created_step.name} - parallel_group: {created_step.parallel_group}")
                
            except Exception as e:
                print(f"Error creating pipeline steps: {e}")
                print(f"Step data causing error: {step_data}")
                raise
    
    def _map_step_type(self, frontend_step_type):
        """æ˜ å°„å‰ç«¯æ­¥éª¤ç±»å‹åˆ°PipelineStepæ¨¡å‹çš„choices"""
        # å®šä¹‰æ”¯æŒçš„æ­¥éª¤ç±»å‹ - ä¿æŒä¸PipelineStep.STEP_TYPE_CHOICESä¸€è‡´
        valid_step_types = [
            'fetch_code', 'build', 'test', 'security_scan',
            'deploy', 'ansible', 'notify', 'custom', 'script',
            # Docker æ­¥éª¤ç±»å‹
            'docker_build', 'docker_run', 'docker_push', 'docker_pull',
            # Kubernetes æ­¥éª¤ç±»å‹
            'k8s_deploy', 'k8s_scale', 'k8s_delete', 'k8s_wait',
            'k8s_exec', 'k8s_logs',
            # å…¶ä»–é«˜çº§æ­¥éª¤ç±»å‹
            'approval', 'condition'
        ]
        
        # å¦‚æœå‰ç«¯ä¼ æ¥çš„ç±»å‹åœ¨æ”¯æŒåˆ—è¡¨ä¸­ï¼Œç›´æ¥ä½¿ç”¨
        if frontend_step_type in valid_step_types:
            return frontend_step_type
        
        # å¦åˆ™æ˜ å°„åˆ°customç±»å‹ä½œä¸ºå…œåº•
        return 'custom'

class PipelineListSerializer(serializers.ModelSerializer):
    """Lighter serializer for list views"""
    project_name = serializers.CharField(source='project.name', read_only=True)
    created_by_username = serializers.CharField(source='created_by.username', read_only=True)
    steps_count = serializers.IntegerField(source='steps.count', read_only=True)
    runs_count = serializers.IntegerField(source='runs.count', read_only=True)
    
    # æ–°å¢ï¼šæ‰§è¡Œæ¨¡å¼ç›¸å…³å­—æ®µ
    execution_tool_name = serializers.CharField(source='execution_tool.name', read_only=True)
    execution_tool_type = serializers.CharField(source='execution_tool.tool_type', read_only=True)
    
    class Meta:
        model = Pipeline
        fields = [
            'id', 'name', 'description', 'status', 'is_active',
            'project', 'project_name', 'created_by_username',
            'created_at', 'updated_at', 'steps_count', 'runs_count',
            # æ–°å¢ï¼šæ‰§è¡Œæ¨¡å¼ç›¸å…³å­—æ®µ
            'execution_mode', 'execution_tool', 'execution_tool_name', 
            'execution_tool_type', 'tool_job_name'
        ]


class PipelineToolMappingSerializer(serializers.ModelSerializer):
    """æµæ°´çº¿ä¸å·¥å…·æ˜ å°„åºåˆ—åŒ–å™¨"""
    
    pipeline_name = serializers.CharField(source='pipeline.name', read_only=True)
    tool_name = serializers.CharField(source='tool.name', read_only=True)
    tool_type = serializers.CharField(source='tool.tool_type', read_only=True)
    
    class Meta:
        model = PipelineToolMapping
        fields = [
            'id', 'pipeline', 'pipeline_name', 'tool', 'tool_name', 'tool_type',
            'external_job_id', 'external_job_name', 'auto_sync', 'last_sync_at',
            'sync_status', 'created_at', 'updated_at'
        ]
        read_only_fields = ['id', 'last_sync_at', 'created_at', 'updated_at']


# æ–°å¢é«˜çº§å·¥ä½œæµåŠŸèƒ½åºåˆ—åŒ–å™¨

class ParallelGroupSerializer(serializers.ModelSerializer):
    """å¹¶è¡Œç»„åºåˆ—åŒ–å™¨"""
    steps = serializers.ListField(
        child=serializers.IntegerField(),
        required=False,
        allow_empty=True,
        write_only=False,
        help_text="æ­¥éª¤IDåˆ—è¡¨"
    )
    
    class Meta:
        model = ParallelGroup
        fields = [
            'id', 'name', 'description', 'pipeline', 'sync_policy',
            'timeout_seconds', 'steps', 'created_at', 'updated_at'
        ]
        read_only_fields = ['created_at', 'updated_at']
    
    def to_representation(self, instance):
        """è‡ªå®šä¹‰åºåˆ—åŒ–è¾“å‡ºï¼ŒåŒ…å«å…³è”çš„æ­¥éª¤"""
        data = super().to_representation(instance)
        
        # è·å–å±äºè¯¥å¹¶è¡Œç»„çš„æ­¥éª¤IDåˆ—è¡¨
        group_id_str = str(instance.id)
        steps = instance.pipeline.steps.filter(parallel_group=group_id_str)
        data['steps'] = [step.id for step in steps]
        
        return data
    
    def create(self, validated_data):
        """åˆ›å»ºå¹¶è¡Œç»„å¹¶å¤„ç†æ­¥éª¤å…³è”"""
        # æå–stepsæ•°æ®
        steps_data = validated_data.pop('steps', [])
        
        # åˆ›å»ºå¹¶è¡Œç»„ï¼ˆä¸åŒ…å«stepså­—æ®µï¼‰
        parallel_group = super().create(validated_data)
        
        # å¤„ç†æ­¥éª¤å…³è”
        if steps_data:
            self._update_step_associations(parallel_group, steps_data)
        
        return parallel_group
    
    def update(self, instance, validated_data):
        """æ›´æ–°å¹¶è¡Œç»„å¹¶å¤„ç†æ­¥éª¤å…³è”"""
        # æå–stepsæ•°æ®
        steps_data = validated_data.pop('steps', None)
        
        # æ›´æ–°å¹¶è¡Œç»„åŸºæœ¬ä¿¡æ¯
        parallel_group = super().update(instance, validated_data)
        
        # å¦‚æœæä¾›äº†stepsæ•°æ®ï¼Œæ›´æ–°æ­¥éª¤å…³è”
        if steps_data is not None:
            self._update_step_associations(parallel_group, steps_data)
        
        return parallel_group
        
        # å¦‚æœæä¾›äº†stepsæ•°æ®ï¼Œæ›´æ–°æ­¥éª¤å…³è”
        if steps_data is not None:
            self._update_step_associations(parallel_group, steps_data)
        
        return parallel_group
    
    def _update_step_associations(self, parallel_group, steps_data):
        """æ›´æ–°æ­¥éª¤ä¸å¹¶è¡Œç»„çš„å…³è”"""
        from .models import PipelineStep
        
        # ç¡®ä¿å¹¶è¡Œç»„æœ‰æœ‰æ•ˆçš„ID
        if not parallel_group.id:
            print(f"âŒ å¹¶è¡Œç»„æ²¡æœ‰æœ‰æ•ˆçš„IDï¼Œæ— æ³•å…³è”æ­¥éª¤")
            return
        
        # å°† parallel_group.id è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå› ä¸º parallel_group å­—æ®µæ˜¯ CharField
        group_id_str = str(parallel_group.id)
        
        print(f"ğŸ”— æ›´æ–°å¹¶è¡Œç»„ {parallel_group.id} çš„æ­¥éª¤å…³è”: {steps_data}")
        
        # 1. æ¸…é™¤è¯¥å¹¶è¡Œç»„çš„æ‰€æœ‰ç°æœ‰å…³è”
        cleared_count = PipelineStep.objects.filter(
            pipeline=parallel_group.pipeline,
            parallel_group=group_id_str
        ).update(parallel_group='')
        
        print(f"âœ… å·²æ¸…é™¤å¹¶è¡Œç»„ {parallel_group.id} çš„ {cleared_count} ä¸ªç°æœ‰å…³è”")
        
        # 2. è®¾ç½®æ–°çš„å…³è”
        if steps_data:
            updated_count = PipelineStep.objects.filter(
                pipeline=parallel_group.pipeline,
                id__in=steps_data
            ).update(parallel_group=group_id_str)
            
            print(f"âœ… å·²å°† {updated_count} ä¸ªæ­¥éª¤å…³è”åˆ°å¹¶è¡Œç»„ {parallel_group.id}")
            
            # éªŒè¯æ›´æ–°ç»“æœ
            associated_steps = PipelineStep.objects.filter(
                pipeline=parallel_group.pipeline,
                parallel_group=group_id_str
            )
            
            print(f"ğŸ” éªŒè¯: å¹¶è¡Œç»„ {parallel_group.id} ç°åœ¨åŒ…å« {associated_steps.count()} ä¸ªæ­¥éª¤")
            for step in associated_steps:
                print(f"  - æ­¥éª¤ {step.name} (ID: {step.id})")
        else:
            print(f"ğŸ“ å¹¶è¡Œç»„ {parallel_group.id} æ²¡æœ‰åˆ†é…ä»»ä½•æ­¥éª¤")


class ApprovalRequestSerializer(serializers.ModelSerializer):
    """å®¡æ‰¹è¯·æ±‚åºåˆ—åŒ–å™¨"""
    
    pipeline_name = serializers.CharField(source='pipeline.name', read_only=True)
    step_name = serializers.CharField(source='step.name', read_only=True)
    requester_username = serializers.CharField(source='requester.username', read_only=True)
    
    class Meta:
        model = ApprovalRequest
        fields = [
            'id', 'pipeline', 'pipeline_name', 'step', 'step_name',
            'execution_id', 'requester', 'requester_username',
            'approvers', 'required_approvals', 'status', 'approval_message',
            'timeout_hours', 'auto_approve_on_timeout',
            'approved_by', 'approved_at', 'response_comment',
            'created_at', 'updated_at'
        ]
        read_only_fields = ['id', 'approved_by', 'approved_at', 'created_at', 'updated_at']


class WorkflowExecutionSerializer(serializers.ModelSerializer):
    """å·¥ä½œæµæ‰§è¡Œåºåˆ—åŒ–å™¨"""
    
    pipeline_name = serializers.CharField(source='pipeline.name', read_only=True)
    current_step_name = serializers.CharField(source='current_step.name', read_only=True)
    
    class Meta:
        model = WorkflowExecution
        fields = [
            'id', 'pipeline', 'pipeline_name', 'execution_id',
            'status', 'trigger_data', 'context_variables', 'step_results',
            'current_step', 'current_step_name', 'failed_steps',
            'pending_approvals', 'recovery_point',
            'started_at', 'completed_at', 'created_at'
        ]
        read_only_fields = ['id', 'created_at']


class StepExecutionHistorySerializer(serializers.ModelSerializer):
    """æ­¥éª¤æ‰§è¡Œå†å²åºåˆ—åŒ–å™¨"""
    
    step_name = serializers.CharField(source='step.name', read_only=True)
    
    class Meta:
        model = StepExecutionHistory
        fields = [
            'id', 'workflow_execution', 'step', 'step_name',
            'status', 'retry_count', 'max_retries',
            'logs', 'error_message', 'output_data',
            'started_at', 'completed_at', 'duration_seconds',
            'created_at'
        ]
        read_only_fields = ['id', 'created_at']


class WorkflowAnalysisSerializer(serializers.Serializer):
    """å·¥ä½œæµåˆ†æç»“æœåºåˆ—åŒ–å™¨"""
    
    total_steps = serializers.IntegerField()
    parallel_groups = serializers.IntegerField()
    approval_steps = serializers.IntegerField()
    conditional_steps = serializers.IntegerField()
    estimated_duration_minutes = serializers.FloatField(required=False)
    critical_path = serializers.ListField(child=serializers.IntegerField(), required=False)
    potential_bottlenecks = serializers.ListField(child=serializers.CharField(), required=False)
    
    
class WorkflowMetricsSerializer(serializers.Serializer):
    """å·¥ä½œæµæŒ‡æ ‡åºåˆ—åŒ–å™¨"""
    
    total_steps = serializers.IntegerField()
    parallel_steps = serializers.IntegerField()
    conditional_steps = serializers.IntegerField()
    approval_steps = serializers.IntegerField()
    estimated_duration = serializers.FloatField()
    complexity_score = serializers.FloatField()
    critical_path = serializers.ListField(child=serializers.IntegerField())
    
    
class ExecutionRecoverySerializer(serializers.Serializer):
    """æ‰§è¡Œæ¢å¤åºåˆ—åŒ–å™¨"""
    
    from_step_id = serializers.IntegerField()
    skip_failed = serializers.BooleanField(default=False)
    modify_parameters = serializers.BooleanField(default=False)
    parameters = serializers.JSONField(default=dict)
    recovery_strategy = serializers.ChoiceField(
        choices=['continue', 'restart_from', 'skip_and_continue'],
        default='continue'
    )
    force_retry = serializers.BooleanField(default=False)
    custom_timeout = serializers.IntegerField(required=False)
    
    
class ApprovalResponseSerializer(serializers.Serializer):
    """å®¡æ‰¹å“åº”åºåˆ—åŒ–å™¨"""
    
    action = serializers.ChoiceField(choices=['approve', 'reject'])
    comment = serializers.CharField(required=False, allow_blank=True)
