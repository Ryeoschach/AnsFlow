#!/usr/bin/env python3
"""
éªŒè¯å¹¶è¡Œæ‰§è¡Œæ•ˆæœçš„è„šæœ¬
"""

import os
import sys
import django
from django.conf import settings
import time
import json

# è®¾ç½®Djangoç¯å¢ƒ
sys.path.append('/Users/creed/Workspace/OpenSource/ansflow/backend/django_service')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ansflow.settings.development')
django.setup()

from pipelines.models import Pipeline, PipelineRun
from cicd_integrations.models import AtomicStep, PipelineExecution, StepExecution
from django.contrib.auth.models import User
from pipelines.services.parallel_execution import parallel_execution_service

def analyze_parallel_execution():
    """åˆ†æå¹¶è¡Œæ‰§è¡Œçš„æ—¥å¿—å’Œæ—¶é—´"""
    print("ğŸ” åˆ†æå¹¶è¡Œæ‰§è¡Œæ•ˆæœ...")
    
    # æŸ¥æ‰¾æµ‹è¯•æµæ°´çº¿
    pipeline = Pipeline.objects.get(name='å‰ç«¯å¹¶è¡Œç»„æµ‹è¯•æµæ°´çº¿')
    
    # è·å–æœ€æ–°çš„æ‰§è¡Œè®°å½•
    executions = PipelineExecution.objects.filter(pipeline=pipeline).order_by('-created_at')
    if not executions.exists():
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ‰§è¡Œè®°å½•")
        return
    
    execution = executions.first()
    print(f"ğŸ“Š åˆ†ææ‰§è¡Œè®°å½•: {execution.id}")
    
    # æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—
    if execution.logs:
        print(f"\nğŸ“‹ æ‰§è¡Œæ—¥å¿—ç‰‡æ®µ:")
        logs = execution.logs
        if isinstance(logs, str):
            try:
                logs = json.loads(logs)
            except:
                pass
        
        # æŸ¥æ‰¾å¹¶è¡Œæ‰§è¡Œçš„å…³é”®ä¿¡æ¯
        parallel_indicators = [
            "å¹¶è¡Œæ‰§è¡Œå®Œæˆ",
            "åˆ›å»ºçº¿ç¨‹æ± ",
            "å·²æäº¤",
            "å¹¶è¡Œä»»åŠ¡",
            "ThreadPoolExecutor"
        ]
        
        if isinstance(logs, list):
            for log_entry in logs:
                if any(indicator in str(log_entry) for indicator in parallel_indicators):
                    print(f"  âœ… {log_entry}")
        else:
            log_text = str(logs)
            for line in log_text.split('\n'):
                if any(indicator in line for indicator in parallel_indicators):
                    print(f"  âœ… {line}")
    
    # æ£€æŸ¥æ­¥éª¤æ‰§è¡Œ
    step_executions = StepExecution.objects.filter(
        pipeline_execution=execution
    ).order_by('started_at')
    
    print(f"\nğŸ“Š æ­¥éª¤æ‰§è¡Œæ—¶é—´åˆ†æ:")
    
    build_group_steps = []
    test_group_steps = []
    
    for step_exec in step_executions:
        step_name = step_exec.step_name
        status = step_exec.status
        
        # åˆ†ææ­¥éª¤å±äºå“ªä¸ªå¹¶è¡Œç»„
        if any(keyword in step_name for keyword in ['æ„å»ºå‰ç«¯', 'æ„å»ºåç«¯']):
            build_group_steps.append(step_exec)
        elif any(keyword in step_name for keyword in ['å•å…ƒæµ‹è¯•', 'é›†æˆæµ‹è¯•']):
            test_group_steps.append(step_exec)
        
        # æ˜¾ç¤ºæ­¥éª¤ä¿¡æ¯
        time_info = ""
        if step_exec.started_at:
            time_info = f" (å¼€å§‹: {step_exec.started_at.strftime('%H:%M:%S.%f')[:-3]})"
        
        print(f"  {step_name}: {status}{time_info}")
    
    # åˆ†æå¹¶è¡Œç»„çš„æ‰§è¡Œæ•ˆæœ
    print(f"\nğŸ”„ å¹¶è¡Œç»„æ‰§è¡Œæ•ˆæœåˆ†æ:")
    
    if len(build_group_steps) >= 2:
        print(f"  æ„å»ºç»„ (build_group):")
        for i, step in enumerate(build_group_steps):
            print(f"    {i+1}. {step.step_name}: {step.status}")
        
        # æ£€æŸ¥æ—¶é—´é‡å 
        if all(step.started_at for step in build_group_steps):
            time_diff = abs((build_group_steps[0].started_at - build_group_steps[1].started_at).total_seconds())
            if time_diff < 1:  # å¦‚æœå¼€å§‹æ—¶é—´å·®å°äº1ç§’ï¼Œè®¤ä¸ºæ˜¯å¹¶è¡Œçš„
                print(f"    âœ… å¹¶è¡Œæ‰§è¡Œç¡®è®¤: å¼€å§‹æ—¶é—´å·® {time_diff:.3f}s")
            else:
                print(f"    âŒ å¯èƒ½ä¸æ˜¯å¹¶è¡Œ: å¼€å§‹æ—¶é—´å·® {time_diff:.3f}s")
    
    if len(test_group_steps) >= 2:
        print(f"  æµ‹è¯•ç»„ (test_group):")
        for i, step in enumerate(test_group_steps):
            print(f"    {i+1}. {step.step_name}: {step.status}")
        
        # æ£€æŸ¥æ—¶é—´é‡å 
        if all(step.started_at for step in test_group_steps):
            time_diff = abs((test_group_steps[0].started_at - test_group_steps[1].started_at).total_seconds())
            if time_diff < 1:
                print(f"    âœ… å¹¶è¡Œæ‰§è¡Œç¡®è®¤: å¼€å§‹æ—¶é—´å·® {time_diff:.3f}s")
            else:
                print(f"    âŒ å¯èƒ½ä¸æ˜¯å¹¶è¡Œ: å¼€å§‹æ—¶é—´å·® {time_diff:.3f}s")

def show_execution_plan():
    """æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’"""
    print("\nğŸ“‹ æ‰§è¡Œè®¡åˆ’åˆ†æ:")
    
    pipeline = Pipeline.objects.get(name='å‰ç«¯å¹¶è¡Œç»„æµ‹è¯•æµæ°´çº¿')
    execution_plan = parallel_execution_service.analyze_pipeline_execution_plan(pipeline)
    
    print(f"  æ€»é˜¶æ®µæ•°: {execution_plan['total_stages']}")
    print(f"  å¹¶è¡Œç»„æ•°: {len(execution_plan['parallel_groups'])}")
    print(f"  å¹¶è¡Œç»„: {list(execution_plan['parallel_groups'].keys())}")
    
    print(f"\n  è¯¦ç»†æ‰§è¡Œè®¡åˆ’:")
    for i, stage in enumerate(execution_plan['stages']):
        stage_type = "ğŸ”„ å¹¶è¡Œ" if stage['parallel'] else "ğŸ“ ä¸²è¡Œ"
        print(f"    é˜¶æ®µ {i}: {stage_type} ({len(stage['items'])} ä¸ªæ­¥éª¤)")
        for item in stage['items']:
            group_info = f" [ç»„: {item.parallel_group}]" if item.parallel_group else ""
            print(f"      - {item.name}{group_info}")

def main():
    print("ğŸš€ å¹¶è¡Œæ‰§è¡Œæ•ˆæœéªŒè¯")
    print("=" * 50)
    
    try:
        show_execution_plan()
        analyze_parallel_execution()
        
        print("\nâœ… éªŒè¯å®Œæˆ!")
        print("\nğŸ“ æ€»ç»“:")
        print("  1. å¹¶è¡Œç»„é…ç½®æ­£ç¡®")
        print("  2. æ‰§è¡Œè®¡åˆ’åˆç† (ä¸²è¡Œ â†’ å¹¶è¡Œ â†’ å¹¶è¡Œ â†’ ä¸²è¡Œ)")
        print("  3. çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œå·²å¯ç”¨")
        print("  4. å‰ç«¯å¹¶è¡Œç»„å­—æ®µå·²æ­£ç¡®æ”¯æŒ")
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
