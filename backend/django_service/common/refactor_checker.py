#!/usr/bin/env python3
"""
æ‰§è¡Œæ—¥å¿—é‡æ„æ£€æŸ¥è„šæœ¬
ç”¨äºè¯†åˆ«é¡¹ç›®ä¸­éœ€è¦ä½¿ç”¨ExecutionLoggeré‡æ„çš„ä»£ç æ¨¡å¼
"""

import os
import re
from pathlib import Path

# éœ€è¦æ£€æŸ¥çš„é‡å¤ä»£ç æ¨¡å¼
PATTERNS_TO_REFACTOR = [
    # çŠ¶æ€è®¾ç½®æ¨¡å¼
    r'\.status\s*=\s*[\'"]running[\'"]',
    r'\.status\s*=\s*[\'"]success[\'"]',
    r'\.status\s*=\s*[\'"]failed[\'"]',
    r'\.status\s*=\s*[\'"]completed[\'"]',
    
    # æ—¶é—´è®¾ç½®æ¨¡å¼
    r'\.started_at\s*=\s*timezone\.now\(\)',
    r'\.completed_at\s*=\s*timezone\.now\(\)',
    
    # æ—¥å¿—è®¾ç½®æ¨¡å¼
    r'\.stdout\s*=\s*result\.stdout',
    r'\.stderr\s*=\s*result\.stderr',
    r'\.return_code\s*=\s*result\.returncode',
    r'\.logs\s*=\s*',
    
    # å¼‚å¸¸å¤„ç†æ¨¡å¼
    r'except subprocess\.TimeoutExpired:',
    r'execution\.status\s*=\s*[\'"]failed[\'"].*timeout',
]

# éœ€è¦æ£€æŸ¥çš„æ–‡ä»¶æ‰©å±•å
FILE_EXTENSIONS = ['.py']

# éœ€è¦æ’é™¤çš„ç›®å½•
EXCLUDE_DIRS = [
    '__pycache__',
    '.git',
    'migrations',
    'common',  # æ’é™¤æˆ‘ä»¬åˆšåˆ›å»ºçš„commonç›®å½•
    'venv',
    'env',
    'node_modules'
]

def find_files_to_check(root_dir):
    """æŸ¥æ‰¾éœ€è¦æ£€æŸ¥çš„Pythonæ–‡ä»¶"""
    files_to_check = []
    
    for root, dirs, files in os.walk(root_dir):
        # æ’é™¤æŒ‡å®šç›®å½•
        dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
        
        for file in files:
            if any(file.endswith(ext) for ext in FILE_EXTENSIONS):
                files_to_check.append(os.path.join(root, file))
    
    return files_to_check

def check_file_for_patterns(file_path):
    """æ£€æŸ¥æ–‡ä»¶ä¸­æ˜¯å¦åŒ…å«éœ€è¦é‡æ„çš„æ¨¡å¼"""
    matches = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
            
            for i, line in enumerate(lines, 1):
                for pattern in PATTERNS_TO_REFACTOR:
                    if re.search(pattern, line, re.IGNORECASE):
                        matches.append({
                            'line_number': i,
                            'line_content': line.strip(),
                            'pattern': pattern
                        })
    
    except (UnicodeDecodeError, PermissionError):
        # è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶
        pass
    
    return matches

def generate_refactor_report(root_dir):
    """ç”Ÿæˆé‡æ„æŠ¥å‘Š"""
    print("ğŸ” æ‰§è¡Œæ—¥å¿—é‡æ„æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 60)
    print()
    
    files_to_check = find_files_to_check(root_dir)
    files_with_patterns = {}
    total_matches = 0
    
    for file_path in files_to_check:
        matches = check_file_for_patterns(file_path)
        if matches:
            rel_path = os.path.relpath(file_path, root_dir)
            files_with_patterns[rel_path] = matches
            total_matches += len(matches)
    
    if not files_with_patterns:
        print("âœ… æœªå‘ç°éœ€è¦é‡æ„çš„ä»£ç æ¨¡å¼")
        return
    
    print(f"ğŸ“Š æ€»å…±å‘ç° {len(files_with_patterns)} ä¸ªæ–‡ä»¶åŒ…å« {total_matches} ä¸ªéœ€è¦é‡æ„çš„ä»£ç æ¨¡å¼")
    print()
    
    # æŒ‰ä¼˜å…ˆçº§æ’åºæ–‡ä»¶
    priority_files = []
    for file_path, matches in files_with_patterns.items():
        priority = calculate_priority(file_path, matches)
        priority_files.append((priority, file_path, matches))
    
    priority_files.sort(reverse=True)
    
    for priority, file_path, matches in priority_files:
        print(f"ğŸ”¥ {file_path} (ä¼˜å…ˆçº§: {priority})")
        print(f"   å‘ç° {len(matches)} ä¸ªéœ€è¦é‡æ„çš„æ¨¡å¼:")
        
        for match in matches[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªåŒ¹é…
            print(f"   ğŸ“ ç¬¬{match['line_number']}è¡Œ: {match['line_content']}")
        
        if len(matches) > 5:
            print(f"   ... è¿˜æœ‰ {len(matches) - 5} ä¸ªåŒ¹é…")
        
        print()
    
    print("ğŸ’¡ é‡æ„å»ºè®®:")
    print("1. ä¼˜å…ˆé‡æ„é«˜ä¼˜å…ˆçº§æ–‡ä»¶")
    print("2. ä½¿ç”¨ ExecutionLogger æ›¿æ¢é‡å¤çš„æ—¥å¿—è®°å½•ä»£ç ")
    print("3. å‚è€ƒ common/execution_logger_usage.md äº†è§£ä½¿ç”¨æ–¹æ³•")
    print("4. æµ‹è¯•æ¯ä¸ªé‡æ„çš„æ–‡ä»¶ä»¥ç¡®ä¿åŠŸèƒ½æ­£å¸¸")

def calculate_priority(file_path, matches):
    """è®¡ç®—æ–‡ä»¶é‡æ„ä¼˜å…ˆçº§"""
    priority = len(matches)  # åŸºç¡€ä¼˜å…ˆçº§ = åŒ¹é…æ•°é‡
    
    # æ ¸å¿ƒæ‰§è¡Œå™¨æ–‡ä»¶ä¼˜å…ˆçº§æ›´é«˜
    if 'executor' in file_path.lower():
        priority += 20
    
    # ä»»åŠ¡æ–‡ä»¶ä¼˜å…ˆçº§è¾ƒé«˜
    if 'tasks.py' in file_path:
        priority += 15
    
    # æœåŠ¡æ–‡ä»¶ä¼˜å…ˆçº§è¾ƒé«˜
    if 'services' in file_path:
        priority += 10
    
    # é›†æˆæ–‡ä»¶ä¼˜å…ˆçº§ä¸­ç­‰
    if 'integration' in file_path:
        priority += 5
    
    return priority

def suggest_refactoring(file_path, matches):
    """ä¸ºç‰¹å®šæ–‡ä»¶æä¾›é‡æ„å»ºè®®"""
    suggestions = []
    
    status_patterns = [m for m in matches if '.status' in m['line_content']]
    time_patterns = [m for m in matches if 'started_at' in m['line_content'] or 'completed_at' in m['line_content']]
    result_patterns = [m for m in matches if any(field in m['line_content'] for field in ['stdout', 'stderr', 'return_code'])]
    
    if status_patterns and time_patterns:
        suggestions.append("å¯ä»¥ä½¿ç”¨ ExecutionLogger.start_execution() å’Œ ExecutionLogger.complete_execution()")
    
    if result_patterns:
        suggestions.append("å¯ä»¥å°† subprocess ç»“æœç›´æ¥ä¼ é€’ç»™ ExecutionLogger.complete_execution()")
    
    timeout_patterns = [m for m in matches if 'timeout' in m['line_content'].lower()]
    if timeout_patterns:
        suggestions.append("å¯ä»¥ä½¿ç”¨ ExecutionLogger.timeout_execution() å¤„ç†è¶…æ—¶")
    
    return suggestions

if __name__ == "__main__":
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)  # ä¸Šä¸€çº§ç›®å½•
    
    print(f"æ£€æŸ¥ç›®å½•: {project_root}")
    print()
    
    generate_refactor_report(project_root)
