#!/usr/bin/env python3
"""
AnsFlow å¹¶è¡Œç»„åŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¹¶è¡Œç»„çš„åˆ›å»ºã€æ‰§è¡Œå’Œç›‘æ§
"""

import asyncio
import time
import json
from datetime import datetime
from typing import Dict, List, Any

class ParallelGroupDemo:
    """å¹¶è¡Œç»„åŠŸèƒ½æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.demo_results = []
    
    def create_demo_pipeline(self) -> Dict[str, Any]:
        """åˆ›å»ºæ¼”ç¤ºç”¨çš„æµæ°´çº¿"""
        # æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„CI/CDæµæ°´çº¿
        steps = [
            # ç¬¬ä¸€é˜¶æ®µï¼šä»£ç æ£€å‡º
            {
                'id': 'checkout',
                'name': 'ä»£ç æ£€å‡º',
                'type': 'fetch_code',
                'order': 1,
                'estimated_duration': 2.0,
                'parameters': {'repository': 'https://github.com/example/project.git'}
            },
            # ç¬¬äºŒé˜¶æ®µï¼šå¹¶è¡Œæµ‹è¯•ç»„
            {
                'id': 'unit_test',
                'name': 'å•å…ƒæµ‹è¯•',
                'type': 'test',
                'order': 2,
                'parallel_group': 'test_group',
                'estimated_duration': 8.0,
                'parameters': {'test_type': 'unit', 'coverage': True}
            },
            {
                'id': 'integration_test',
                'name': 'é›†æˆæµ‹è¯•',
                'type': 'test',
                'order': 2,
                'parallel_group': 'test_group',
                'estimated_duration': 12.0,
                'parameters': {'test_type': 'integration', 'database': 'postgres'}
            },
            {
                'id': 'security_scan',
                'name': 'å®‰å…¨æ‰«æ',
                'type': 'security',
                'order': 2,
                'parallel_group': 'test_group',
                'estimated_duration': 6.0,
                'parameters': {'scan_type': 'sast', 'tools': ['sonarqube', 'snyk']}
            },
            {
                'id': 'lint_check',
                'name': 'ä»£ç æ£€æŸ¥',
                'type': 'lint',
                'order': 2,
                'parallel_group': 'test_group',
                'estimated_duration': 3.0,
                'parameters': {'linters': ['eslint', 'prettier', 'pylint']}
            },
            # ç¬¬ä¸‰é˜¶æ®µï¼šæ„å»º
            {
                'id': 'build_app',
                'name': 'æ„å»ºåº”ç”¨',
                'type': 'build',
                'order': 3,
                'estimated_duration': 10.0,
                'parameters': {'build_tool': 'docker', 'optimize': True}
            },
            # ç¬¬å››é˜¶æ®µï¼šå¹¶è¡Œéƒ¨ç½²ç»„
            {
                'id': 'deploy_staging',
                'name': 'éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ',
                'type': 'deploy',
                'order': 4,
                'parallel_group': 'deploy_group',
                'estimated_duration': 5.0,
                'parameters': {'environment': 'staging', 'health_check': True}
            },
            {
                'id': 'deploy_preview',
                'name': 'éƒ¨ç½²é¢„è§ˆç¯å¢ƒ',
                'type': 'deploy',
                'order': 4,
                'parallel_group': 'deploy_group',
                'estimated_duration': 4.0,
                'parameters': {'environment': 'preview', 'temporary': True}
            }
        ]
        
        parallel_groups = [
            {
                'id': 'test_group',
                'name': 'æµ‹è¯•å¹¶è¡Œç»„',
                'description': 'å¹¶è¡Œæ‰§è¡Œå„ç§æµ‹è¯•ä»¥æé«˜æ•ˆç‡',
                'sync_policy': 'wait_all',
                'timeout_seconds': 900,
                'order': 2,
                'color': '#52c41a'
            },
            {
                'id': 'deploy_group',
                'name': 'éƒ¨ç½²å¹¶è¡Œç»„',
                'description': 'åŒæ—¶éƒ¨ç½²åˆ°å¤šä¸ªç¯å¢ƒ',
                'sync_policy': 'wait_all',
                'timeout_seconds': 300,
                'order': 4,
                'color': '#1890ff'
            }
        ]
        
        return {
            'name': 'AnsFlow å¹¶è¡Œç»„æ¼”ç¤ºæµæ°´çº¿',
            'description': 'å±•ç¤ºå¹¶è¡Œç»„åŠŸèƒ½çš„å®Œæ•´CI/CDæµæ°´çº¿',
            'steps': steps,
            'parallel_groups': parallel_groups
        }
    
    async def simulate_step_execution(self, step: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ­¥éª¤æ‰§è¡Œ"""
        step_name = step['name']
        duration = step['estimated_duration']
        
        print(f"  ğŸš€ å¼€å§‹æ‰§è¡Œ: {step_name}")
        
        # æ¨¡æ‹Ÿæ‰§è¡Œè¿‡ç¨‹
        start_time = time.time()
        
        # åˆ†æ®µæ˜¾ç¤ºè¿›åº¦
        segments = 4
        for i in range(segments):
            await asyncio.sleep(duration / segments)
            progress = ((i + 1) / segments) * 100
            print(f"     ğŸ“Š {step_name} è¿›åº¦: {progress:.0f}%")
        
        execution_time = time.time() - start_time
        
        # æ¨¡æ‹Ÿå¶å°”çš„å¤±è´¥ï¼ˆ5%æ¦‚ç‡ï¼‰
        import random
        success = random.random() > 0.05
        
        if success:
            print(f"  âœ… å®Œæˆ: {step_name} ({execution_time:.2f}s)")
            return {
                'success': True,
                'execution_time': execution_time,
                'output': f'{step_name} æ‰§è¡ŒæˆåŠŸ'
            }
        else:
            print(f"  âŒ å¤±è´¥: {step_name} ({execution_time:.2f}s)")
            return {
                'success': False,
                'execution_time': execution_time,
                'error': f'{step_name} æ¨¡æ‹Ÿæ‰§è¡Œå¤±è´¥'
            }
    
    async def execute_parallel_group(self, group: Dict[str, Any], group_steps: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰§è¡Œå¹¶è¡Œç»„"""
        group_name = group['name']
        sync_policy = group['sync_policy']
        
        print(f"\nğŸ”€ å¼€å§‹å¹¶è¡Œç»„: {group_name}")
        print(f"   ç­–ç•¥: {sync_policy}, æ­¥éª¤æ•°: {len(group_steps)}")
        
        start_time = time.time()
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ­¥éª¤
        tasks = [self.simulate_step_execution(step) for step in group_steps]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # åˆ†æç»“æœ
        successful_steps = 0
        failed_steps = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"   âŒ æ­¥éª¤å¼‚å¸¸: {group_steps[i]['name']} - {result}")
                failed_steps += 1
            elif result.get('success', False):
                successful_steps += 1
            else:
                failed_steps += 1
        
        # æ ¹æ®åŒæ­¥ç­–ç•¥åˆ¤æ–­æˆåŠŸ
        group_success = False
        if sync_policy == 'wait_all':
            group_success = failed_steps == 0
        elif sync_policy == 'wait_any':
            group_success = successful_steps > 0
        elif sync_policy == 'fail_fast':
            group_success = failed_steps == 0
        
        status_emoji = "âœ…" if group_success else "âŒ"
        print(f"\n{status_emoji} å¹¶è¡Œç»„å®Œæˆ: {group_name}")
        print(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f}s")
        print(f"   æˆåŠŸæ­¥éª¤: {successful_steps}/{len(group_steps)}")
        
        return {
            'group_name': group_name,
            'success': group_success,
            'execution_time': execution_time,
            'successful_steps': successful_steps,
            'total_steps': len(group_steps),
            'results': results
        }
    
    async def execute_demo_pipeline(self) -> Dict[str, Any]:
        """æ‰§è¡Œæ¼”ç¤ºæµæ°´çº¿"""
        pipeline = self.create_demo_pipeline()
        
        print("=" * 80)
        print(f"ğŸ¬ AnsFlow å¹¶è¡Œç»„åŠŸèƒ½æ¼”ç¤º")
        print(f"æµæ°´çº¿: {pipeline['name']}")
        print(f"æè¿°: {pipeline['description']}")
        print("=" * 80)
        
        steps = pipeline['steps']
        parallel_groups = {group['id']: group for group in pipeline['parallel_groups']}
        
        # åˆ†ææ‰§è¡Œè®¡åˆ’
        execution_plan = self.analyze_execution_plan(steps, parallel_groups)
        
        print(f"\nğŸ“‹ æ‰§è¡Œè®¡åˆ’:")
        for stage in execution_plan['stages']:
            stage_type = "å¹¶è¡Œ" if stage['is_parallel'] else "é¡ºåº"
            print(f"   é˜¶æ®µ {stage['order']}: {stage_type} - {len(stage['steps'])} æ­¥éª¤")
        
        total_start_time = time.time()
        stage_results = []
        
        # æŒ‰é˜¶æ®µæ‰§è¡Œ
        for stage in execution_plan['stages']:
            stage_start_time = time.time()
            
            if stage['is_parallel']:
                # å¹¶è¡Œæ‰§è¡Œ
                group_info = parallel_groups[stage['group_id']]
                result = await self.execute_parallel_group(group_info, stage['steps'])
                stage_results.append(result)
                
                if not result['success']:
                    print(f"\nğŸ’¥ æµæ°´çº¿å¤±è´¥äºå¹¶è¡Œç»„: {group_info['name']}")
                    break
            else:
                # é¡ºåºæ‰§è¡Œ
                print(f"\nâ¡ï¸ é¡ºåºæ‰§è¡Œé˜¶æ®µ {stage['order']}")
                for step in stage['steps']:
                    result = await self.simulate_step_execution(step)
                    if not result['success']:
                        print(f"\nğŸ’¥ æµæ°´çº¿å¤±è´¥äºæ­¥éª¤: {step['name']}")
                        stage_results.append({'success': False, 'failed_step': step['name']})
                        break
                else:
                    stage_time = time.time() - stage_start_time
                    stage_results.append({
                        'success': True,
                        'execution_time': stage_time,
                        'stage_type': 'sequential'
                    })
        
        total_time = time.time() - total_start_time
        
        # ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
        return self.generate_execution_report(pipeline, stage_results, total_time)
    
    def analyze_execution_plan(self, steps: List[Dict[str, Any]], parallel_groups: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ‰§è¡Œè®¡åˆ’"""
        # æŒ‰orderåˆ†ç»„
        order_groups = {}
        for step in steps:
            order = step['order']
            if order not in order_groups:
                order_groups[order] = []
            order_groups[order].append(step)
        
        stages = []
        for order in sorted(order_groups.keys()):
            stage_steps = order_groups[order]
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¹¶è¡Œç»„
            parallel_group_id = stage_steps[0].get('parallel_group')
            is_parallel = parallel_group_id is not None
            
            if is_parallel:
                # ç¡®ä¿æ‰€æœ‰æ­¥éª¤éƒ½å±äºåŒä¸€ä¸ªå¹¶è¡Œç»„
                assert all(step.get('parallel_group') == parallel_group_id for step in stage_steps)
            
            stages.append({
                'order': order,
                'is_parallel': is_parallel,
                'group_id': parallel_group_id,
                'steps': stage_steps
            })
        
        return {'stages': stages}
    
    def generate_execution_report(self, pipeline: Dict[str, Any], stage_results: List[Dict[str, Any]], total_time: float) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š"""
        successful_stages = sum(1 for result in stage_results if result.get('success', False))
        total_stages = len(stage_results)
        
        overall_success = successful_stages == total_stages
        
        print("\n" + "=" * 80)
        print("ğŸ“Š æµæ°´çº¿æ‰§è¡ŒæŠ¥å‘Š")
        print("=" * 80)
        print(f"æµæ°´çº¿åç§°: {pipeline['name']}")
        print(f"æ‰§è¡ŒçŠ¶æ€: {'âœ… æˆåŠŸ' if overall_success else 'âŒ å¤±è´¥'}")
        print(f"æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}s")
        print(f"æˆåŠŸé˜¶æ®µ: {successful_stages}/{total_stages}")
        
        # å¹¶è¡Œç»„æ€§èƒ½åˆ†æ
        parallel_results = [r for r in stage_results if 'group_name' in r]
        if parallel_results:
            print(f"\nğŸ”€ å¹¶è¡Œç»„æ€§èƒ½:")
            for result in parallel_results:
                efficiency = (result['successful_steps'] / result['total_steps']) * 100
                print(f"   {result['group_name']}: {result['execution_time']:.2f}s, {efficiency:.1f}% æ•ˆç‡")
        
        # æ€§èƒ½å»ºè®®
        print(f"\nğŸ’¡ æ€§èƒ½åˆ†æ:")
        if total_time < 30:
            print("   âœ… æ‰§è¡Œæ—¶é—´ç†æƒ³ï¼Œå¹¶è¡Œç»„ä¼˜åŒ–æ•ˆæœæ˜¾è‘—")
        elif total_time < 60:
            print("   âš ï¸ æ‰§è¡Œæ—¶é—´å¯æ¥å—ï¼Œè€ƒè™‘è¿›ä¸€æ­¥ä¼˜åŒ–")
        else:
            print("   ğŸ”¥ æ‰§è¡Œæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®å¢åŠ å¹¶è¡Œåº¦")
        
        if overall_success:
            print("   âœ… æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸï¼Œæµæ°´çº¿ç¨³å®šå¯é ")
        else:
            print("   âŒ å­˜åœ¨å¤±è´¥æ­¥éª¤ï¼Œå»ºè®®å¢åŠ é‡è¯•æœºåˆ¶")
        
        print("=" * 80)
        
        return {
            'pipeline_name': pipeline['name'],
            'success': overall_success,
            'total_time': total_time,
            'successful_stages': successful_stages,
            'total_stages': total_stages,
            'parallel_efficiency': self.calculate_parallel_efficiency(stage_results),
            'timestamp': datetime.now().isoformat()
        }
    
    def calculate_parallel_efficiency(self, stage_results: List[Dict[str, Any]]) -> float:
        """è®¡ç®—å¹¶è¡Œæ‰§è¡Œæ•ˆç‡"""
        parallel_results = [r for r in stage_results if 'group_name' in r]
        if not parallel_results:
            return 0.0
        
        total_efficiency = 0.0
        for result in parallel_results:
            efficiency = (result['successful_steps'] / result['total_steps']) * 100
            total_efficiency += efficiency
        
        return total_efficiency / len(parallel_results)

async def main():
    """ä¸»å‡½æ•°"""
    demo = ParallelGroupDemo()
    
    print("ğŸ­ AnsFlow å¹¶è¡Œç»„åŠŸèƒ½æ¼”ç¤ºå¼€å§‹...")
    print("è¿™ä¸ªæ¼”ç¤ºå°†å±•ç¤º:")
    print("  1. å¹¶è¡Œç»„çš„åˆ›å»ºå’Œé…ç½®")
    print("  2. å¹¶è¡Œæ­¥éª¤çš„æ‰§è¡Œè¿‡ç¨‹")
    print("  3. æ€§èƒ½ä¼˜åŒ–æ•ˆæœ")
    print("  4. æ‰§è¡Œç»“æœåˆ†æ")
    print()
    
    try:
        result = await demo.execute_demo_pipeline()
        
        print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
        print(f"æ•´ä½“æˆåŠŸç‡: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±è´¥'}")
        print(f"å¹¶è¡Œæ•ˆç‡: {result['parallel_efficiency']:.1f}%")
        print(f"æ€»æ‰§è¡Œæ—¶é—´: {result['total_time']:.2f}s")
        
        # ä¿å­˜ç»“æœ
        with open(f"demo_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 'w') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° demo_result_*.json")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
