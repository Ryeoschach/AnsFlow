# AnsFlow日志系统使用指南

## 概述

AnsFlow统一日志系统已完成Phase 2开发，提供：
- 统一的Django/FastAPI日志管理
- Redis Streams实时日志缓冲
- WebSocket实时日志推送
- 结构化JSON日志格式
- 自动敏感数据脱敏
- 企业级日志轮转和存储

## 快速开始

### 1. 基础日志记录

```python
import logging
from common.logging_config import get_logger, log_with_context

# 获取日志器
logger = get_logger('ansflow.mymodule')

# 基础日志记录
logger.info('用户登录成功')
logger.warning('缓存连接较慢')
logger.error('API调用失败')

# 带上下文的日志记录
log_with_context(
    logger, 
    'INFO', 
    '订单创建成功',
    request=request,
    extra={'order_id': 12345, 'amount': 99.99},
    labels=['order', 'payment']
)
```

### 2. Redis日志流使用

```python
import asyncio
from common.redis_logging import RedisLogStreams

# 初始化Redis日志流
redis_logger = RedisLogStreams()

# 连接Redis
if redis_logger.connect():
    # 异步写入日志
    await redis_logger.log_async(
        level='INFO',
        message='系统事件记录',
        service='django_service',
        user_id=123,
        action='create_pipeline'
    )
    
    # 读取最近日志
    recent_logs = redis_logger.read_logs_stream(count=50)
    print(f"获取到 {len(recent_logs)} 条日志")
```

### 3. WebSocket实时日志

```javascript
// 前端JavaScript
import { RealTimeLogClient } from './services/realTimeLogClient';

const logClient = new RealTimeLogClient('ws://localhost:8000/ws/logs/');

// 监听日志消息
logClient.on('log', (logData) => {
    console.log('新日志:', logData);
    // 更新UI显示
});

// 监听连接状态
logClient.on('connectionStatus', (status) => {
    console.log('连接状态:', status);
});

// 设置日志过滤器
logClient.setFilter({
    levels: ['ERROR', 'WARNING', 'INFO'],
    services: ['django_service'],
    keywords: ['用户', '订单']
});

// 连接WebSocket
logClient.connect();
```

### 4. 缓冲日志管理

```python
from common.websocket_logging import BufferedLogManager, LogFilter

# 创建缓冲管理器
buffer_manager = BufferedLogManager(buffer_size=1000)

# 添加日志到缓冲区
buffer_manager.add_log({
    'level': 'INFO',
    'message': '用户操作记录',
    'timestamp': '2025-08-05T06:40:00Z',
    'user_id': 123
})

# 获取过滤后的日志
log_filter = LogFilter(
    levels=['ERROR', 'WARNING'],
    services=['django_service'],
    keywords=['错误', '异常']
)

filtered_logs = buffer_manager.get_recent_logs(count=100, log_filter=log_filter)
```

## 配置管理

### 环境变量配置

```bash
# .env文件
LOG_LEVEL=INFO
LOG_DIR=/path/to/logs
LOG_FORMAT=json
LOGGING_ENABLE_REDIS=true
LOGGING_ENABLE_WEBSOCKET=true
LOG_ROTATION=daily
LOG_RETENTION_DAYS=30

# Redis配置
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_LOG_DB=1
```

### Django设置

```python
# settings/base.py
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'ansflow_json': {
            '()': 'common.logging_config.AnsFlowJSONFormatter',
        },
    },
    'handlers': {
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'ansflow_json',
        },
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.TimedRotatingFileHandler',
            'filename': BASE_DIR / 'logs' / 'django.log',
            'formatter': 'ansflow_json',
        },
    },
    'loggers': {
        'ansflow': {
            'handlers': ['console', 'file'],
            'level': 'DEBUG',
            'propagate': False,
        },
    },
}
```

## 日志格式

### 标准日志结构

```json
{
    "timestamp": "2025-08-05T06:40:00.123Z",
    "level": "INFO",
    "service": "django_service",
    "module": "ansflow.pipelines",
    "message": "流水线执行完成",
    "trace_id": "req_abc12345",
    "user_id": 123,
    "user_name": "admin",
    "ip": "192.168.1.100",
    "method": "POST",
    "path": "/api/pipelines/execute",
    "status_code": 200,
    "response_time_ms": 1250,
    "labels": ["pipeline", "execution", "success"],
    "extra": {
        "pipeline_id": 456,
        "steps_count": 5,
        "execution_time": "00:02:30"
    }
}
```

### 敏感数据脱敏

系统自动脱敏以下字段：
- password, passwd, pwd
- token, key, secret
- authorization, cookie, session
- csrf

```json
{
    "user_data": {
        "username": "admin",
        "password": "adm*******",  // 自动脱敏
        "token": "******"          // 自动脱敏
    }
}
```

## 性能优化

### Redis配置建议

```python
# Redis连接池配置
REDIS_LOG_CONFIG = {
    'host': 'localhost',
    'port': 6379,
    'db': 1,
    'max_connections': 20,
    'retry_on_timeout': True,
    'health_check_interval': 30
}

# 日志流配置
LOG_STREAM_CONFIG = {
    'stream_name': 'ansflow:logs',
    'max_len': 10000,         # 流最大长度
    'batch_size': 100,        # 批处理大小
    'retention_hours': 24     # 数据保留时间
}
```

### 文件日志轮转

```python
# 按级别分离日志文件
LOGGING_FILE_CONFIG = {
    'error_log': 'logs/error.log',      # 只记录ERROR
    'warning_log': 'logs/warning.log',  # 只记录WARNING
    'info_log': 'logs/info.log',        # 只记录INFO
    'debug_log': 'logs/debug.log'       # 只记录DEBUG
}

# 轮转策略
LOG_ROTATION = {
    'when': 'midnight',    # 每天午夜轮转
    'interval': 1,         # 轮转间隔
    'backupCount': 30,     # 保留30天
    'encoding': 'utf-8'
}
```

## 监控和告警

### 日志级别监控

```python
# 错误级别自动告警
ERROR_ALERT_CONFIG = {
    'error_threshold': 10,      # 5分钟内超过10个ERROR
    'warning_threshold': 50,    # 5分钟内超过50个WARNING
    'time_window': 300,         # 时间窗口（秒）
}

# 集成Prometheus指标
from django_prometheus import metrics

error_counter = metrics.Counter(
    'ansflow_logs_error_total',
    'Total number of error logs',
    labelnames=['service', 'module']
)
```

### 健康检查

```python
# 日志系统健康检查
def check_logging_health():
    checks = {
        'redis_connection': False,
        'file_write': False,
        'websocket_ready': False
    }
    
    # 检查Redis连接
    try:
        redis_logger = RedisLogStreams()
        checks['redis_connection'] = redis_logger.connect()
    except Exception:
        pass
    
    # 检查文件写入
    try:
        test_logger = get_logger('health_check')
        test_logger.info('Health check test')
        checks['file_write'] = True
    except Exception:
        pass
    
    return checks
```

## 故障排除

### 常见问题

1. **Redis连接失败**
   - 检查Redis服务状态
   - 验证连接配置
   - 查看防火墙设置

2. **日志文件权限问题**
   - 确保日志目录写权限
   - 检查磁盘空间
   - 验证文件路径

3. **WebSocket连接断开**
   - 检查网络连接
   - 验证认证状态
   - 查看服务器负载

### 调试模式

```python
# 启用详细日志
import logging
logging.getLogger('common.redis_logging').setLevel(logging.DEBUG)
logging.getLogger('common.websocket_logging').setLevel(logging.DEBUG)

# 测试日志系统
def test_logging_system():
    from common.logging_config import AnsFlowLoggingConfig
    from common.redis_logging import RedisLogStreams
    from common.websocket_logging import BufferedLogManager
    
    print("🚀 开始日志系统测试...")
    
    # 测试配置
    config = AnsFlowLoggingConfig()
    print(f"✅ 配置加载: {config.log_dir}")
    
    # 测试Redis
    redis_logger = RedisLogStreams()
    if redis_logger.connect():
        print("✅ Redis连接成功")
    else:
        print("❌ Redis连接失败")
    
    # 测试缓冲管理器
    buffer_manager = BufferedLogManager()
    buffer_manager.add_log({'test': 'data'})
    print(f"✅ 缓冲管理器: {len(buffer_manager.get_recent_logs())} 条日志")
    
    print("🎯 测试完成")
```

## 最佳实践

### 1. 日志级别使用

- **DEBUG**: 详细的调试信息，仅开发环境使用
- **INFO**: 一般信息，业务流程关键节点
- **WARNING**: 警告信息，需要关注但不影响运行
- **ERROR**: 错误信息，需要立即处理

### 2. 上下文信息

始终包含足够的上下文信息：
```python
log_with_context(
    logger, 'INFO', '订单处理完成',
    request=request,
    extra={
        'order_id': order.id,
        'user_id': order.user_id,
        'amount': order.amount,
        'processing_time': processing_time
    },
    labels=['order', 'payment', 'success']
)
```

### 3. 异步日志使用

对于高频率的日志写入，使用异步方式：
```python
# 高性能异步日志
async def process_batch_orders(orders):
    for order in orders:
        await redis_logger.log_async(
            level='INFO',
            message=f'处理订单 {order.id}',
            service='order_service',
            order_id=order.id
        )
```

### 4. 错误处理

始终包含异常处理的日志：
```python
try:
    result = process_payment(order)
    logger.info('支付处理成功', extra={'order_id': order.id, 'amount': order.amount})
except PaymentError as e:
    logger.error('支付处理失败', extra={
        'order_id': order.id,
        'error_code': e.code,
        'error_message': str(e)
    })
    raise
```

## 总结

AnsFlow日志系统Phase 2已完成所有核心功能开发和测试，系统稳定可靠，可投入生产环境使用。系统提供了完整的日志管理解决方案，支持高性能、实时性和可观测性要求。

如有问题或需要技术支持，请参考故障排除章节或联系开发团队。
