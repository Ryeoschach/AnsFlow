#!/usr/bin/env python3
"""
AnsFlow ç”Ÿäº§ç¯å¢ƒå¥åº·æ£€æŸ¥è„šæœ¬
ç”¨äºç›‘æ§ç”Ÿäº§ç¯å¢ƒçš„æœåŠ¡çŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡
"""

import requests
import time
import json
import sys
from datetime import datetime
import redis
import pika

class AnsFlowHealthChecker:
    """AnsFlow ç”Ÿäº§ç¯å¢ƒå¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "overall_status": "checking",
            "services": {},
            "performance": {},
            "alerts": []
        }
        
        # ç”Ÿäº§ç¯å¢ƒé…ç½®
        self.django_url = "http://localhost:8000"
        self.fastapi_url = "http://localhost:8001"
        self.redis_url = "redis://localhost:6379"
        self.rabbitmq_url = "amqp://ansflow_prod:password@localhost:5672/ansflow_vhost"
    
    def check_django_service(self):
        """æ£€æŸ¥ Django æœåŠ¡çŠ¶æ€"""
        try:
            # å¥åº·æ£€æŸ¥ç«¯ç‚¹
            response = requests.get(f"{self.django_url}/api/v1/health/", timeout=10)
            if response.status_code == 200:
                self.results["services"]["django"] = {
                    "status": "âœ… healthy",
                    "response_time_ms": response.elapsed.total_seconds() * 1000,
                    "data": response.json()
                }
            else:
                self.results["services"]["django"] = {
                    "status": f"âŒ unhealthy (HTTP {response.status_code})",
                    "response_time_ms": response.elapsed.total_seconds() * 1000
                }
                self.results["alerts"].append("Django service returned non-200 status")
        except Exception as e:
            self.results["services"]["django"] = {
                "status": f"âŒ error: {str(e)}"
            }
            self.results["alerts"].append(f"Django service check failed: {str(e)}")
    
    def check_fastapi_service(self):
        """æ£€æŸ¥ FastAPI æœåŠ¡çŠ¶æ€"""
        try:
            # å¥åº·æ£€æŸ¥
            start_time = time.time()
            response = requests.get(f"{self.fastapi_url}/health", timeout=10)
            response_time = (time.time() - start_time) * 1000
            
            if response.status_code == 200:
                self.results["services"]["fastapi"] = {
                    "status": "âœ… healthy",
                    "response_time_ms": response_time,
                    "data": response.json()
                }
                
                # æ€§èƒ½æµ‹è¯•
                self._test_fastapi_performance()
            else:
                self.results["services"]["fastapi"] = {
                    "status": f"âŒ unhealthy (HTTP {response.status_code})",
                    "response_time_ms": response_time
                }
                self.results["alerts"].append("FastAPI service returned non-200 status")
        except Exception as e:
            self.results["services"]["fastapi"] = {
                "status": f"âŒ error: {str(e)}"
            }
            self.results["alerts"].append(f"FastAPI service check failed: {str(e)}")
    
    def _test_fastapi_performance(self):
        """æµ‹è¯• FastAPI æ€§èƒ½"""
        try:
            # å¹¶å‘è¯·æ±‚æµ‹è¯•
            import asyncio
            import aiohttp
            
            async def make_request(session):
                async with session.get(f"{self.fastapi_url}/health") as response:
                    return await response.json()
            
            async def run_concurrent_test():
                async with aiohttp.ClientSession() as session:
                    tasks = [make_request(session) for _ in range(10)]
                    start_time = time.time()
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    end_time = time.time()
                    
                    successful = sum(1 for r in results if not isinstance(r, Exception))
                    total_time = (end_time - start_time) * 1000
                    
                    return {
                        "total_requests": len(tasks),
                        "successful": successful,
                        "total_time_ms": total_time,
                        "avg_time_ms": total_time / len(tasks),
                        "requests_per_second": len(tasks) / (total_time / 1000)
                    }
            
            perf_result = asyncio.run(run_concurrent_test())
            self.results["performance"]["fastapi_concurrent"] = perf_result
            
            # æ€§èƒ½è­¦å‘Š
            if perf_result["avg_time_ms"] > 100:
                self.results["alerts"].append("FastAPI average response time > 100ms")
            if perf_result["requests_per_second"] < 20:
                self.results["alerts"].append("FastAPI requests/second < 20")
                
        except Exception as e:
            self.results["performance"]["fastapi_concurrent"] = {"error": str(e)}
    
    def check_redis_service(self):
        """æ£€æŸ¥ Redis æœåŠ¡çŠ¶æ€"""
        try:
            databases = {
                "default": redis.Redis.from_url(f"{self.redis_url}/1"),
                "session": redis.Redis.from_url(f"{self.redis_url}/3"),
                "api": redis.Redis.from_url(f"{self.redis_url}/4"),
                "pipeline": redis.Redis.from_url(f"{self.redis_url}/5"),
                "channels": redis.Redis.from_url(f"{self.redis_url}/2")
            }
            
            redis_status = {}
            total_memory = 0
            
            for db_name, client in databases.items():
                try:
                    # æµ‹è¯•è¿æ¥
                    start_time = time.time()
                    client.ping()
                    latency = (time.time() - start_time) * 1000
                    
                    # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
                    info = client.info('memory')
                    used_memory = info['used_memory']
                    total_memory += used_memory
                    
                    redis_status[db_name] = {
                        "status": "âœ… connected",
                        "latency_ms": round(latency, 2),
                        "memory_mb": round(used_memory / 1024 / 1024, 2)
                    }
                    
                    # å»¶è¿Ÿè­¦å‘Š
                    if latency > 5:
                        self.results["alerts"].append(f"Redis {db_name} latency > 5ms")
                        
                except Exception as e:
                    redis_status[db_name] = {"status": f"âŒ error: {str(e)}"}
                    self.results["alerts"].append(f"Redis {db_name} connection failed")
            
            self.results["services"]["redis"] = redis_status
            self.results["performance"]["redis_total_memory_mb"] = round(total_memory / 1024 / 1024, 2)
            
            # å†…å­˜ä½¿ç”¨è­¦å‘Š
            if total_memory > 512 * 1024 * 1024:  # 512MB
                self.results["alerts"].append("Redis total memory usage > 512MB")
                
        except Exception as e:
            self.results["services"]["redis"] = {"error": str(e)}
            self.results["alerts"].append(f"Redis check failed: {str(e)}")
    
    def check_rabbitmq_service(self):
        """æ£€æŸ¥ RabbitMQ æœåŠ¡çŠ¶æ€"""
        try:
            connection = pika.BlockingConnection(pika.URLParameters(self.rabbitmq_url))
            channel = connection.channel()
            
            # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
            queues = ['high_priority', 'medium_priority', 'low_priority']
            queue_status = {}
            
            for queue_name in queues:
                try:
                    method = channel.queue_declare(queue=queue_name, passive=True)
                    queue_status[queue_name] = {
                        "status": "âœ… active",
                        "message_count": method.method.message_count,
                        "consumer_count": method.method.consumer_count
                    }
                    
                    # é˜Ÿåˆ—ç§¯å‹è­¦å‘Š
                    if method.method.message_count > 1000:
                        self.results["alerts"].append(f"Queue {queue_name} has {method.method.message_count} pending messages")
                        
                except Exception as e:
                    queue_status[queue_name] = {"status": f"âŒ error: {str(e)}"}
            
            connection.close()
            self.results["services"]["rabbitmq"] = queue_status
            
        except Exception as e:
            self.results["services"]["rabbitmq"] = {"error": str(e)}
            self.results["alerts"].append(f"RabbitMQ check failed: {str(e)}")
    
    def check_system_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            
            # CPU ä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            
            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            
            self.results["performance"]["system"] = {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "disk_percent": (disk.used / disk.total) * 100,
                "memory_available_gb": round(memory.available / 1024 / 1024 / 1024, 2),
                "disk_free_gb": round(disk.free / 1024 / 1024 / 1024, 2)
            }
            
            # ç³»ç»Ÿèµ„æºè­¦å‘Š
            if cpu_percent > 80:
                self.results["alerts"].append(f"High CPU usage: {cpu_percent}%")
            if memory.percent > 80:
                self.results["alerts"].append(f"High memory usage: {memory.percent}%")
            if (disk.used / disk.total) * 100 > 80:
                self.results["alerts"].append(f"High disk usage: {(disk.used / disk.total) * 100:.1f}%")
                
        except ImportError:
            self.results["performance"]["system"] = {"error": "psutil not installed"}
        except Exception as e:
            self.results["performance"]["system"] = {"error": str(e)}
    
    def check_parallel_execution_performance(self):
        """æ£€æŸ¥å¹¶è¡Œæ‰§è¡Œæ€§èƒ½å’ŒçŠ¶æ€"""
        try:
            # æ£€æŸ¥å½“å‰è¿è¡Œçš„å¹¶è¡Œç»„
            response = requests.get(f"{self.django_url}/api/v1/executions/parallel-status/", timeout=10)
            
            if response.status_code == 200:
                parallel_data = response.json()
                
                active_parallel_groups = parallel_data.get('active_parallel_groups', 0)
                avg_parallel_execution_time = parallel_data.get('avg_execution_time_seconds', 0)
                parallel_success_rate = parallel_data.get('success_rate_percent', 0)
                concurrent_workers = parallel_data.get('concurrent_workers', 0)
                
                self.results["performance"]["parallel_execution"] = {
                    "active_parallel_groups": active_parallel_groups,
                    "avg_execution_time_seconds": avg_parallel_execution_time,
                    "success_rate_percent": parallel_success_rate,
                    "concurrent_workers": concurrent_workers,
                    "status": "âœ… operational"
                }
                
                # å¹¶è¡Œæ‰§è¡Œæ€§èƒ½è­¦å‘Š
                if active_parallel_groups > 10:
                    self.results["alerts"].append(f"High parallel groups load: {active_parallel_groups} active")
                if avg_parallel_execution_time > 300:  # 5åˆ†é’Ÿ
                    self.results["alerts"].append(f"Long parallel execution time: {avg_parallel_execution_time}s average")
                if parallel_success_rate < 90:
                    self.results["alerts"].append(f"Low parallel success rate: {parallel_success_rate}%")
                if concurrent_workers > 50:
                    self.results["alerts"].append(f"High concurrent workers: {concurrent_workers}")
                
                # æ£€æŸ¥Jenkinså¹¶è¡Œè½¬æ¢æ€§èƒ½
                self._check_jenkins_parallel_performance()
                
                # æ£€æŸ¥å¹¶è¡Œç»„API
                self._check_parallel_groups_api()
                
            else:
                self.results["performance"]["parallel_execution"] = {
                    "status": f"âŒ API error (HTTP {response.status_code})"
                }
                self.results["alerts"].append("Parallel execution status API unavailable")
                
        except Exception as e:
            self.results["performance"]["parallel_execution"] = {
                "status": f"âŒ check failed: {str(e)}"
            }
            self.results["alerts"].append(f"Parallel execution check failed: {str(e)}")
    
    def _check_jenkins_parallel_performance(self):
        """æ£€æŸ¥Jenkinså¹¶è¡Œè½¬æ¢æ€§èƒ½"""
        try:
            # æµ‹è¯•Jenkinså¹¶è¡Œç»„æ£€æµ‹åŠŸèƒ½
            test_response = requests.post(
                f"{self.django_url}/api/v1/cicd/pipelines/preview/",
                json={
                    "pipeline_id": 2,
                    "preview_mode": False,
                    "execution_mode": "remote"
                },
                timeout=10
            )
            
            if test_response.status_code == 200:
                preview_data = test_response.json()
                workflow_summary = preview_data.get('workflow_summary', {})
                jenkinsfile = preview_data.get('jenkinsfile', '')
                
                # æ£€æŸ¥å¹¶è¡Œç»„æ£€æµ‹
                total_steps = workflow_summary.get('total_steps', 0)
                has_parallel_syntax = 'parallel {' in jenkinsfile
                parallel_group_count = jenkinsfile.count('parallel {')
                
                self.results["performance"]["jenkins_parallel"] = {
                    "parallel_detection_working": has_parallel_syntax,
                    "total_steps_detected": total_steps,
                    "parallel_groups_detected": parallel_group_count,
                    "jenkinsfile_generation": "âœ… successful" if jenkinsfile else "âŒ failed",
                    "database_integration": "âœ… working" if workflow_summary.get('data_source') == 'database' else "âŒ failed"
                }
                
                # Jenkinså¹¶è¡Œç»„åŠŸèƒ½è­¦å‘Š
                if not has_parallel_syntax:
                    self.results["alerts"].append("Jenkins parallel group detection not working")
                if total_steps == 0:
                    self.results["alerts"].append("Jenkins pipeline preview returns 0 steps")
                if parallel_group_count == 0:
                    self.results["alerts"].append("No parallel groups detected in Jenkins pipeline")
                    
            else:
                self.results["performance"]["jenkins_parallel"] = {
                    "status": f"âŒ Pipeline preview API error (HTTP {test_response.status_code})"
                }
                self.results["alerts"].append("Jenkins pipeline preview API unavailable")
            
            # å°è¯•è·å–Jenkinsç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                stats_response = requests.get(f"{self.django_url}/api/v1/tools/jenkins/parallel-stats/", timeout=5)
                if stats_response.status_code == 200:
                    jenkins_stats = stats_response.json()
                    self.results["performance"]["jenkins_parallel"].update({
                        "conversion_success_rate": jenkins_stats.get('conversion_success_rate', 0),
                        "avg_conversion_time_ms": jenkins_stats.get('avg_conversion_time_ms', 0),
                        "active_builds": jenkins_stats.get('active_builds', 0)
                    })
            except:
                pass  # Jenkinsç»Ÿè®¡APIå¯èƒ½ä¸å­˜åœ¨ï¼Œè¿™æ˜¯å¯é€‰çš„
            
        except Exception as e:
            self.results["performance"]["jenkins_parallel"] = {
                "status": f"âŒ check failed: {str(e)}"
            }
            self.results["alerts"].append(f"Jenkins parallel check failed: {str(e)}")

    def _check_parallel_groups_api(self):
        """æ£€æŸ¥å¹¶è¡Œç»„APIåŠŸèƒ½"""
        try:
            # ä½¿ç”¨Django shellæ¨¡æ‹Ÿå¹¶è¡Œç»„APIè°ƒç”¨ï¼Œå› ä¸ºéœ€è¦è®¤è¯
            import subprocess
            
            django_cmd = '''
import sys, os
sys.path.append('/Users/creed/Workspace/OpenSource/ansflow/backend/django_service')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ansflow.settings')
import django
django.setup()

from pipelines.models import Pipeline
pipeline = Pipeline.objects.get(id=2)
steps = pipeline.steps.all().order_by('order')

parallel_groups = {}
for step in steps:
    if step.parallel_group:
        group_name = step.parallel_group
        if group_name not in parallel_groups:
            parallel_groups[group_name] = {'id': group_name, 'name': group_name, 'steps': []}
        parallel_groups[group_name]['steps'].append({'id': step.id, 'name': step.name})

print(f"GROUPS:{len(parallel_groups)}")
print(f"STEPS:{len(steps)}")
'''
            
            result = subprocess.run([
                'python3', '-c', django_cmd
            ], capture_output=True, text=True, cwd='/Users/creed/Workspace/OpenSource/ansflow/backend/django_service')
            
            if result.returncode == 0:
                output = result.stdout.strip()
                groups_line = [line for line in output.split('\n') if line.startswith('GROUPS:')]
                steps_line = [line for line in output.split('\n') if line.startswith('STEPS:')]
                
                if groups_line and steps_line:
                    groups_count = int(groups_line[0].split(':')[1])
                    steps_count = int(steps_line[0].split(':')[1])
                    
                    self.results["performance"]["parallel_groups_api"] = {
                        "status": "âœ… working",
                        "groups_detected": groups_count,
                        "total_steps": steps_count,
                        "api_logic": "âœ… fixed" if groups_count > 0 else "âŒ not working"
                    }
                    
                    # APIåŠŸèƒ½è­¦å‘Š
                    if groups_count == 0:
                        self.results["alerts"].append("Parallel groups API returns 0 groups")
                    if steps_count == 0:
                        self.results["alerts"].append("Parallel groups API returns 0 steps")
                else:
                    self.results["performance"]["parallel_groups_api"] = {
                        "status": "âŒ parsing failed"
                    }
            else:
                self.results["performance"]["parallel_groups_api"] = {
                    "status": f"âŒ django shell failed: {result.stderr}"
                }
                
        except Exception as e:
            self.results["performance"]["parallel_groups_api"] = {
                "status": f"âŒ check failed: {str(e)}"
            }

    def run_health_check(self):
        """è¿è¡Œå®Œæ•´çš„å¥åº·æ£€æŸ¥"""
        print("ğŸ¥ AnsFlow ç”Ÿäº§ç¯å¢ƒå¥åº·æ£€æŸ¥")
        print("=" * 50)
        
        # æ‰§è¡Œå„é¡¹æ£€æŸ¥
        print("ğŸ” æ£€æŸ¥ Django æœåŠ¡...")
        self.check_django_service()
        
        print("ğŸ” æ£€æŸ¥ FastAPI æœåŠ¡...")
        self.check_fastapi_service()
        
        print("ğŸ” æ£€æŸ¥ Redis æœåŠ¡...")
        self.check_redis_service()
        
        print("ğŸ” æ£€æŸ¥ RabbitMQ æœåŠ¡...")
        self.check_rabbitmq_service()
        
        print("ğŸ” æ£€æŸ¥ç³»ç»Ÿèµ„æº...")
        self.check_system_resources()
        
        print("ğŸ” æ£€æŸ¥å¹¶è¡Œæ‰§è¡Œæ€§èƒ½...")
        self.check_parallel_execution_performance()
        
        # ç¡®å®šæ•´ä½“çŠ¶æ€
        has_errors = any(
            "âŒ" in str(service) or "error" in str(service).lower()
            for service in self.results["services"].values()
        )
        
        if has_errors:
            self.results["overall_status"] = "âŒ UNHEALTHY"
        elif self.results["alerts"]:
            self.results["overall_status"] = "âš ï¸ WARNING"
        else:
            self.results["overall_status"] = "âœ… HEALTHY"
        
        return self.results
    
    def print_summary(self):
        """æ‰“å°å¥åº·æ£€æŸ¥æ‘˜è¦"""
        print("\n" + "=" * 50)
        print(f"ğŸ“Š å¥åº·æ£€æŸ¥æ‘˜è¦ - {self.results['overall_status']}")
        print("=" * 50)
        
        # æœåŠ¡çŠ¶æ€
        print("\nğŸ”§ æœåŠ¡çŠ¶æ€:")
        for service, status in self.results["services"].items():
            if isinstance(status, dict) and "status" in status:
                print(f"  {service}: {status['status']}")
            else:
                print(f"  {service}: {status}")
        
        # æ€§èƒ½æŒ‡æ ‡
        if self.results["performance"]:
            print("\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
            for metric, value in self.results["performance"].items():
                print(f"  {metric}: {value}")
        
        # è­¦å‘Šä¿¡æ¯
        if self.results["alerts"]:
            print("\nâš ï¸ è­¦å‘Šä¿¡æ¯:")
            for alert in self.results["alerts"]:
                print(f"  - {alert}")
        
        print("\n" + "=" * 50)

def main():
    """ä¸»å‡½æ•°"""
    checker = AnsFlowHealthChecker()
    
    try:
        results = checker.run_health_check()
        checker.print_summary()
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = f"docs/testing/health_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ ¹æ®çŠ¶æ€è®¾ç½®é€€å‡ºç 
        if results["overall_status"] == "âŒ UNHEALTHY":
            sys.exit(1)
        elif results["overall_status"] == "âš ï¸ WARNING":
            sys.exit(2)
        else:
            sys.exit(0)
            
    except Exception as e:
        print(f"\nâŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
