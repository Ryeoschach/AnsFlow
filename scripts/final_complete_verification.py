#!/usr/bin/env python3
"""
ğŸ¯ AnsFlow å¹¶è¡Œç»„åŠŸèƒ½ - æœ€ç»ˆå®Œæ•´éªŒè¯
éªŒè¯ä»é¢„è§ˆåˆ°æ‰§è¡Œçš„å®Œæ•´æ•°æ®æµ
"""

import sys
import os
import json
import subprocess
import time

sys.path.append('/Users/creed/Workspace/OpenSource/ansflow/backend/django_service')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ansflow.settings')

import django
django.setup()

from pipelines.models import Pipeline
from cicd_integrations.models import PipelineExecution
from cicd_integrations.services import UnifiedCICDEngine

def test_complete_parallel_workflow():
    """æµ‹è¯•å®Œæ•´çš„å¹¶è¡Œç»„å·¥ä½œæµ"""
    print("ğŸ¯ AnsFlow å¹¶è¡Œç»„åŠŸèƒ½ - æœ€ç»ˆå®Œæ•´éªŒè¯")
    print("=" * 70)
    
    results = {
        "database_data": False,
        "preview_api": False,
        "jenkins_sync": False,
        "execution_engine": False,
        "frontend_data": False
    }
    
    pipeline_id = 2
    
    # 1. éªŒè¯æ•°æ®åº“æ•°æ®
    print("\nğŸ“‹ 1. éªŒè¯æ•°æ®åº“ä¸­çš„å¹¶è¡Œç»„æ•°æ®")
    try:
        pipeline = Pipeline.objects.get(id=pipeline_id)
        steps = pipeline.steps.all().order_by('order')
        
        parallel_groups = set()
        for step in steps:
            pg = step.parallel_group or ''
            if pg:
                parallel_groups.add(pg)
            print(f"    æ­¥éª¤: {step.name} -> parallel_group: '{pg}'")
        
        print(f"  âœ… æ€»æ­¥éª¤æ•°: {len(steps)}")
        print(f"  âœ… å¹¶è¡Œç»„æ•°: {len(parallel_groups)}")
        
        if len(steps) == 4 and len(parallel_groups) == 1:
            results["database_data"] = True
            print("  ğŸ¯ æ•°æ®åº“æ•°æ®éªŒè¯é€šè¿‡ï¼")
        else:
            print("  âŒ æ•°æ®åº“æ•°æ®éªŒè¯å¤±è´¥")
            
    except Exception as e:
        print(f"  âŒ æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
    
    # 2. éªŒè¯é¢„è§ˆAPI
    print("\nğŸ“‹ 2. éªŒè¯é¢„è§ˆAPI (preview_mode=false)")
    try:
        cmd = [
            'curl', '-s', '-X', 'POST',
            'http://localhost:8000/api/v1/cicd/pipelines/preview/',
            '-H', 'Content-Type: application/json',
            '-d', json.dumps({
                "pipeline_id": pipeline_id,
                "preview_mode": False,
                "execution_mode": "remote"
            })
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        
        workflow_summary = data.get('workflow_summary', {})
        jenkinsfile = data.get('jenkinsfile', '')
        
        total_steps = workflow_summary.get('total_steps', 0)
        has_parallel = 'parallel {' in jenkinsfile
        parallel_count = jenkinsfile.count('parallel {')
        
        print(f"  âœ… æ€»æ­¥éª¤æ•°: {total_steps}")
        print(f"  âœ… åŒ…å«å¹¶è¡Œè¯­æ³•: {has_parallel}")
        print(f"  âœ… å¹¶è¡Œç»„æ•°é‡: {parallel_count}")
        print(f"  âœ… æ•°æ®æº: {workflow_summary.get('data_source', 'unknown')}")
        
        if total_steps == 4 and has_parallel and parallel_count == 1:
            results["preview_api"] = True
            print("  ğŸ¯ é¢„è§ˆAPIéªŒè¯é€šè¿‡ï¼")
        else:
            print("  âŒ é¢„è§ˆAPIéªŒè¯å¤±è´¥")
            
    except Exception as e:
        print(f"  âŒ é¢„è§ˆAPIéªŒè¯å¤±è´¥: {e}")
    
    # 3. éªŒè¯JenkinsåŒæ­¥
    print("\nğŸ“‹ 3. éªŒè¯JenkinsåŒæ­¥æœåŠ¡")
    try:
        from pipelines.services.jenkins_sync import JenkinsPipelineSyncService
        
        class MockJenkinsTool:
            def __init__(self):
                self.tool_type = 'jenkins'
                self.base_url = 'http://mock-jenkins:8080'
                self.username = 'admin'
                self.token = 'mock-token'
        
        jenkins_service = JenkinsPipelineSyncService(MockJenkinsTool())
        pipeline_script = jenkins_service._convert_steps_to_jenkins_script(pipeline)
        
        has_parallel = 'parallel {' in pipeline_script
        parallel_count = pipeline_script.count('parallel {')
        
        print(f"  âœ… Jenkinsè„šæœ¬é•¿åº¦: {len(pipeline_script)} å­—ç¬¦")
        print(f"  âœ… åŒ…å«å¹¶è¡Œè¯­æ³•: {has_parallel}")
        print(f"  âœ… å¹¶è¡Œç»„æ•°é‡: {parallel_count}")
        
        if has_parallel and parallel_count == 1:
            results["jenkins_sync"] = True
            print("  ğŸ¯ JenkinsåŒæ­¥éªŒè¯é€šè¿‡ï¼")
        else:
            print("  âŒ JenkinsåŒæ­¥éªŒè¯å¤±è´¥")
            
    except Exception as e:
        print(f"  âŒ JenkinsåŒæ­¥éªŒè¯å¤±è´¥: {e}")
    
    # 4. éªŒè¯æ‰§è¡Œå¼•æ“
    print("\nğŸ“‹ 4. éªŒè¯æ‰§è¡Œå¼•æ“")
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿæ‰§è¡Œå¯¹è±¡
        execution = type('MockExecution', (), {
            'id': 999,
            'pipeline': pipeline,
            'status': 'pending',
            'parameters': {},  # æ·»åŠ ç¼ºå°‘çš„å‚æ•°
            'definition': {},  # æ·»åŠ å®šä¹‰
            'trigger_data': {}  # æ·»åŠ è§¦å‘æ•°æ®
        })()
        
        engine = UnifiedCICDEngine()
        pipeline_def = engine._build_pipeline_definition_from_atomic_steps(execution)
        
        # æ£€æŸ¥pipeline_defä¸­çš„æ­¥éª¤ï¼ˆè¿™äº›æ˜¯å­—å…¸ï¼Œä¸æ˜¯å¯¹è±¡ï¼‰
        steps_with_parallel = [s for s in pipeline_def.steps if s.get('parallel_group')]
        
        print(f"  âœ… Pipelineå®šä¹‰æ­¥éª¤æ•°: {len(pipeline_def.steps)}")
        print(f"  âœ… åŒ…å«å¹¶è¡Œç»„çš„æ­¥éª¤æ•°: {len(steps_with_parallel)}")
        
        # æ‰“å°æ­¥éª¤è¯¦æƒ…ä»¥ä¾¿è°ƒè¯•
        for i, step in enumerate(pipeline_def.steps):
            print(f"    æ­¥éª¤{i+1}: {step.get('name')} - parallel_group: '{step.get('parallel_group', '')}'")
        
        if len(pipeline_def.steps) == 4 and len(steps_with_parallel) == 2:
            results["execution_engine"] = True
            print("  ğŸ¯ æ‰§è¡Œå¼•æ“éªŒè¯é€šè¿‡ï¼")
        else:
            print("  âŒ æ‰§è¡Œå¼•æ“éªŒè¯å¤±è´¥")
            print(f"    æœŸæœ›: 4ä¸ªæ­¥éª¤ï¼Œ2ä¸ªå¹¶è¡Œæ­¥éª¤")
            print(f"    å®é™…: {len(pipeline_def.steps)}ä¸ªæ­¥éª¤ï¼Œ{len(steps_with_parallel)}ä¸ªå¹¶è¡Œæ­¥éª¤")
            
    except Exception as e:
        print(f"  âŒ æ‰§è¡Œå¼•æ“éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # 5. éªŒè¯å‰ç«¯æ•°æ®ä¼ é€’
    print("\nğŸ“‹ 5. éªŒè¯å‰ç«¯æ•°æ®ä¼ é€’ (preview_mode=true)")
    try:
        # æ¨¡æ‹Ÿå‰ç«¯ä¼ é€’çš„æ•°æ®ï¼ˆä¿®å¤ååº”è¯¥åŒ…å«parallel_groupå­—æ®µï¼‰
        frontend_data = {
            "pipeline_id": pipeline_id,
            "preview_mode": True,
            "execution_mode": "remote",
            "steps": [
                {
                    "name": "1111",
                    "step_type": "custom",
                    "parameters": {},
                    "order": 1,
                    "description": "",
                    "parallel_group": ""
                },
                {
                    "name": "222-1",
                    "step_type": "custom",
                    "parameters": {},
                    "order": 2,
                    "description": "",
                    "parallel_group": "parallel_1752467687202"
                },
                {
                    "name": "222-2",
                    "step_type": "custom",
                    "parameters": {},
                    "order": 3,
                    "description": "",
                    "parallel_group": "parallel_1752467687202"
                },
                {
                    "name": "333",
                    "step_type": "custom",
                    "parameters": {},
                    "order": 4,
                    "description": "",
                    "parallel_group": ""
                }
            ]
        }
        
        cmd = [
            'curl', '-s', '-X', 'POST',
            'http://localhost:8000/api/v1/cicd/pipelines/preview/',
            '-H', 'Content-Type: application/json',
            '-d', json.dumps(frontend_data)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        
        workflow_summary = data.get('workflow_summary', {})
        jenkinsfile = data.get('jenkinsfile', '')
        
        total_steps = workflow_summary.get('total_steps', 0)
        has_parallel = 'parallel {' in jenkinsfile
        parallel_count = jenkinsfile.count('parallel {')
        
        print(f"  âœ… æ€»æ­¥éª¤æ•°: {total_steps}")
        print(f"  âœ… åŒ…å«å¹¶è¡Œè¯­æ³•: {has_parallel}")
        print(f"  âœ… å¹¶è¡Œç»„æ•°é‡: {parallel_count}")
        print(f"  âœ… æ•°æ®æº: {workflow_summary.get('data_source', 'unknown')}")
        
        if total_steps == 4 and has_parallel and parallel_count == 1:
            results["frontend_data"] = True
            print("  ğŸ¯ å‰ç«¯æ•°æ®ä¼ é€’éªŒè¯é€šè¿‡ï¼")
        else:
            print("  âŒ å‰ç«¯æ•°æ®ä¼ é€’éªŒè¯å¤±è´¥")
            
    except Exception as e:
        print(f"  âŒ å‰ç«¯æ•°æ®ä¼ é€’éªŒè¯å¤±è´¥: {e}")
    
    # æœ€ç»ˆç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š æœ€ç»ˆéªŒè¯ç»“æœ:")
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, passed_test in results.items():
        status = "âœ… é€šè¿‡" if passed_test else "âŒ å¤±è´¥"
        print(f"  {test_name.replace('_', ' ').title()}: {status}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AnsFlowå¹¶è¡Œç»„åŠŸèƒ½å®Œå…¨æ­£å¸¸ï¼")
        print("\nğŸš€ åŠŸèƒ½ç‰¹æ€§å·²å®Œå…¨å®ç°:")
        print("  âœ… æ•°æ®åº“æ­£ç¡®å­˜å‚¨å¹¶è¡Œç»„ä¿¡æ¯")
        print("  âœ… é¢„è§ˆAPIæ­£ç¡®æ£€æµ‹å¹¶è¡Œç»„")
        print("  âœ… JenkinsåŒæ­¥æ­£ç¡®ç”Ÿæˆå¹¶è¡Œè¯­æ³•")
        print("  âœ… æ‰§è¡Œå¼•æ“æ­£ç¡®å¤„ç†å¹¶è¡Œç»„")
        print("  âœ… å‰ç«¯æ­£ç¡®ä¼ é€’å¹¶è¡Œç»„æ•°æ®")
        
        print("\nğŸ¯ ç”¨æˆ·ç°åœ¨å¯ä»¥:")
        print("  - åœ¨å‰ç«¯åˆ›å»ºåŒ…å«å¹¶è¡Œç»„çš„æµæ°´çº¿")
        print("  - é¢„è§ˆJenkins Pipelineçš„å¹¶è¡Œè¯­æ³•")
        print("  - æ‰§è¡ŒåŒ…å«å¹¶è¡Œç»„çš„æµæ°´çº¿")
        print("  - ç›‘æ§å¹¶è¡Œç»„çš„æ‰§è¡ŒçŠ¶æ€")
        
        return 0
    else:
        print(f"\nâŒ è¿˜æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        print("\néœ€è¦è¿›ä¸€æ­¥è°ƒè¯•çš„é—®é¢˜:")
        for test_name, passed_test in results.items():
            if not passed_test:
                print(f"  - {test_name.replace('_', ' ').title()}")
        return 1

if __name__ == "__main__":
    sys.exit(test_complete_parallel_workflow())
